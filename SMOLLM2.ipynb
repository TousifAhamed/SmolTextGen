{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f665f5d3e9d47dabaa802647a9ef435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d46187c0f2954e499d89d2743815010e",
              "IPY_MODEL_903db8a472664999913db44119b000e9",
              "IPY_MODEL_4f9fa6e9208c4518b08012efede44522"
            ],
            "layout": "IPY_MODEL_3a45fb902b9942a9976f8c67ace7ae2f"
          }
        },
        "d46187c0f2954e499d89d2743815010e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70515edeb9ff4af795d5ee69f2fb1c7b",
            "placeholder": "​",
            "style": "IPY_MODEL_008b50359b34498b804e64d074102f91",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "903db8a472664999913db44119b000e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10215db5e2db40f6a4547efe7f2fb648",
            "max": 3907,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df7ba48fc3e1407a9b85d9f38c237892",
            "value": 3907
          }
        },
        "4f9fa6e9208c4518b08012efede44522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97147c86f09e4547b5cfe07c123faded",
            "placeholder": "​",
            "style": "IPY_MODEL_7fa67b532e184734b80975f53ea63266",
            "value": " 3.91k/3.91k [00:00&lt;00:00, 228kB/s]"
          }
        },
        "3a45fb902b9942a9976f8c67ace7ae2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70515edeb9ff4af795d5ee69f2fb1c7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "008b50359b34498b804e64d074102f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10215db5e2db40f6a4547efe7f2fb648": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df7ba48fc3e1407a9b85d9f38c237892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97147c86f09e4547b5cfe07c123faded": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fa67b532e184734b80975f53ea63266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "507a674781eb4bfa9cdc6cda9f3af6af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f351a47a278e402881de67bea29aa02f",
              "IPY_MODEL_dc8134ec3932469eb58286f553f611bb",
              "IPY_MODEL_581668bfd46644109124c4a27c9b0791"
            ],
            "layout": "IPY_MODEL_9ebf09c98cd54d55a657e930bb928fa5"
          }
        },
        "f351a47a278e402881de67bea29aa02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73d4a7e75e7348a68223bd77ee24b284",
            "placeholder": "​",
            "style": "IPY_MODEL_3b65e1357cd94cdc985af1694d478617",
            "value": "vocab.json: 100%"
          }
        },
        "dc8134ec3932469eb58286f553f611bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b35a98258c2e42e184f6df86d7b9b572",
            "max": 800662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82ef2da7cf6d489cbab5c0dcb89e174c",
            "value": 800662
          }
        },
        "581668bfd46644109124c4a27c9b0791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f829ef77e8ed470bab2baae34cc23029",
            "placeholder": "​",
            "style": "IPY_MODEL_27b40a09398c401c8faa9e013c3dd370",
            "value": " 801k/801k [00:00&lt;00:00, 5.86MB/s]"
          }
        },
        "9ebf09c98cd54d55a657e930bb928fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73d4a7e75e7348a68223bd77ee24b284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b65e1357cd94cdc985af1694d478617": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b35a98258c2e42e184f6df86d7b9b572": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82ef2da7cf6d489cbab5c0dcb89e174c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f829ef77e8ed470bab2baae34cc23029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27b40a09398c401c8faa9e013c3dd370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "188f8700a2d14c5d86ebb2fc14e5f381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dc3621ceed64e10909c4a5411b645f5",
              "IPY_MODEL_183b9739e4824d649b2a92d3c137300a",
              "IPY_MODEL_f7521f480b7d4e098cb4fbc7b4fb8bab"
            ],
            "layout": "IPY_MODEL_749793d153364a65bfb3aa1dbd497310"
          }
        },
        "8dc3621ceed64e10909c4a5411b645f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_113b6a37c2ab48f78024b4f2beb449aa",
            "placeholder": "​",
            "style": "IPY_MODEL_990d16be91844a988e0d3a2bb4c3832d",
            "value": "merges.txt: 100%"
          }
        },
        "183b9739e4824d649b2a92d3c137300a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77580489b25340949b82a71fc4eca1cd",
            "max": 466391,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9fa659945924c41b16b3406ac948a72",
            "value": 466391
          }
        },
        "f7521f480b7d4e098cb4fbc7b4fb8bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5687904ed79a4b3eb65fc5ced5f0d0a1",
            "placeholder": "​",
            "style": "IPY_MODEL_1056cc7088114047be0f170dc491b9eb",
            "value": " 466k/466k [00:00&lt;00:00, 3.53MB/s]"
          }
        },
        "749793d153364a65bfb3aa1dbd497310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "113b6a37c2ab48f78024b4f2beb449aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "990d16be91844a988e0d3a2bb4c3832d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77580489b25340949b82a71fc4eca1cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9fa659945924c41b16b3406ac948a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5687904ed79a4b3eb65fc5ced5f0d0a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1056cc7088114047be0f170dc491b9eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c242f97209a4a8f8beabd10d209ee30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77e911d7f0b0426781353b20481425a3",
              "IPY_MODEL_87765b5ec39e4389b61a4166d30fd31a",
              "IPY_MODEL_12c966f1ecd74a558e79168f288f1e22"
            ],
            "layout": "IPY_MODEL_680843c588894e75905036eb9c837dfb"
          }
        },
        "77e911d7f0b0426781353b20481425a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55d0ce3331b945f285d2aa0eb020779f",
            "placeholder": "​",
            "style": "IPY_MODEL_43a89cc08446414ab18b88e048392cd9",
            "value": "tokenizer.json: 100%"
          }
        },
        "87765b5ec39e4389b61a4166d30fd31a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_776c19f02c834463a041f3077660ee09",
            "max": 2104556,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc98de438fb04d6da1b26b00f7f5da7f",
            "value": 2104556
          }
        },
        "12c966f1ecd74a558e79168f288f1e22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d9b43a8b4c34d2cbc596976593cc3da",
            "placeholder": "​",
            "style": "IPY_MODEL_d83cd8d496054470a67f0e3107006a24",
            "value": " 2.10M/2.10M [00:00&lt;00:00, 22.3MB/s]"
          }
        },
        "680843c588894e75905036eb9c837dfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55d0ce3331b945f285d2aa0eb020779f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43a89cc08446414ab18b88e048392cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "776c19f02c834463a041f3077660ee09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc98de438fb04d6da1b26b00f7f5da7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d9b43a8b4c34d2cbc596976593cc3da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d83cd8d496054470a67f0e3107006a24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ec2186446e74863afac48eda94bca9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46b5d453d2ed4fe5a799bc4d4c0bda08",
              "IPY_MODEL_14fd2233c0e3457eb03063ffb00c2513",
              "IPY_MODEL_238ca8ebb3e64db29bf8173c985c0bd2"
            ],
            "layout": "IPY_MODEL_4462a3b5eff746f3bd3b49a534f363b9"
          }
        },
        "46b5d453d2ed4fe5a799bc4d4c0bda08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5e8f139532142f2982b0cec20717b1f",
            "placeholder": "​",
            "style": "IPY_MODEL_01e241c1257b4020b4354d80e93316a5",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "14fd2233c0e3457eb03063ffb00c2513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fa33c9fd83c4a60b4fbf7e091f8d6e3",
            "max": 489,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3958f9a214104f81bce5cfebecc2bc1c",
            "value": 489
          }
        },
        "238ca8ebb3e64db29bf8173c985c0bd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d8b2878b7a441098ec9711a926a056c",
            "placeholder": "​",
            "style": "IPY_MODEL_da7485aa6cb04ace8922111c8047617b",
            "value": " 489/489 [00:00&lt;00:00, 41.6kB/s]"
          }
        },
        "4462a3b5eff746f3bd3b49a534f363b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5e8f139532142f2982b0cec20717b1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01e241c1257b4020b4354d80e93316a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fa33c9fd83c4a60b4fbf7e091f8d6e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3958f9a214104f81bce5cfebecc2bc1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d8b2878b7a441098ec9711a926a056c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da7485aa6cb04ace8922111c8047617b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIpKGDqp4gV-"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "import json\n",
        "from typing import Any, Dict\n",
        "import sys\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def load_yaml(file_path: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Load YAML data from a file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the YAML file.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: Parsed YAML data as a dictionary.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the file does not exist.\n",
        "        yaml.YAMLError: If there is an error parsing the YAML.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as yaml_file:\n",
        "            return yaml.safe_load(yaml_file)\n",
        "    except FileNotFoundError:\n",
        "        logger.error(f\"File not found: {file_path}\")\n",
        "        raise\n",
        "    except yaml.YAMLError as e:\n",
        "        logger.error(f\"Error parsing YAML file: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def save_json(data: Dict[str, Any], file_path: str) -> None:\n",
        "    \"\"\"\n",
        "    Save JSON data to a file.\n",
        "\n",
        "    Args:\n",
        "        data (Dict[str, Any]): Data to be saved as JSON.\n",
        "        file_path (str): Path to the output JSON file.\n",
        "\n",
        "    Raises:\n",
        "        IOError: If there is an error writing to the file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
        "            json.dump(data, json_file, indent=2)\n",
        "        logger.info(f\"JSON data successfully saved to {file_path}\")\n",
        "    except IOError as e:\n",
        "        logger.error(f\"Error writing JSON file: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def convert_yaml_to_json(yaml_file_path: str, json_file_path: str) -> None:\n",
        "    \"\"\"\n",
        "    Convert a YAML file to a JSON file.\n",
        "\n",
        "    Args:\n",
        "        yaml_file_path (str): Path to the input YAML file.\n",
        "        json_file_path (str): Path to the output JSON file.\n",
        "\n",
        "    Raises:\n",
        "        Exception: If any error occurs during the conversion process.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load YAML data\n",
        "        yaml_data = load_yaml(yaml_file_path)\n",
        "        logger.info(\"YAML data loaded successfully.\")\n",
        "\n",
        "        # Save JSON data\n",
        "        save_json(yaml_data, json_file_path)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"An error occurred during conversion: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Input and output file paths\n",
        "    input_yaml_file = \"config_smollm2_135M.yaml\"\n",
        "    output_json_file = \"config_smollm2_135M.json\"\n",
        "\n",
        "    # Perform conversion\n",
        "    try:\n",
        "        convert_yaml_to_json(input_yaml_file, output_json_file)\n",
        "    except Exception:\n",
        "        sys.exit(1)  # Exit with a non-zero status code to indicate failure"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def load_json(file_path: str) -> dict:\n",
        "    \"\"\"\n",
        "    Load JSON data from a file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the JSON file.\n",
        "\n",
        "    Returns:\n",
        "        dict: Parsed JSON data as a dictionary.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the file does not exist.\n",
        "        json.JSONDecodeError: If there is an error parsing the JSON.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
        "            return json.load(json_file)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found - {file_path}\")\n",
        "        raise\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error: Invalid JSON format in {file_path} - {e}\")\n",
        "        raise\n",
        "\n",
        "def print_model_architecture(model_config: dict) -> None:\n",
        "    \"\"\"\n",
        "    Print the architecture of the model based on its configuration.\n",
        "\n",
        "    Args:\n",
        "        model_config (dict): The model configuration dictionary.\n",
        "    \"\"\"\n",
        "    print(\"Model Architecture:\")\n",
        "    print(\"-------------------\")\n",
        "    print(f\"Hidden Size: {model_config.get('hidden_size')}\")\n",
        "    print(f\"Number of Hidden Layers: {model_config.get('num_hidden_layers')}\")\n",
        "    print(f\"Number of Attention Heads: {model_config.get('num_attention_heads')}\")\n",
        "    print(f\"Number of Key-Value Heads: {model_config.get('num_key_value_heads')}\")\n",
        "    print(f\"Intermediate Size: {model_config.get('intermediate_size')}\")\n",
        "    print(f\"Hidden Activation: {model_config.get('hidden_act')}\")\n",
        "    print(f\"Maximum Position Embeddings: {model_config.get('max_position_embeddings')}\")\n",
        "    print(f\"RMS Norm Epsilon: {model_config.get('rms_norm_eps')}\")\n",
        "    print(f\"Vocabulary Size: {model_config.get('vocab_size')}\")\n",
        "    print(f\"Use Cache: {model_config.get('use_cache')}\")\n",
        "    print(f\"Tie Word Embeddings: {model_config.get('tie_word_embeddings')}\")\n",
        "    print(f\"Initializer Range: {model_config.get('initializer_range')}\")\n",
        "    print(f\"BOS Token ID: {model_config.get('bos_token_id')}\")\n",
        "    print(f\"EOS Token ID: {model_config.get('eos_token_id')}\")\n",
        "    print(f\"Pad Token ID: {model_config.get('pad_token_id')}\")\n",
        "    print(f\"Pretraining TP: {model_config.get('pretraining_tp')}\")\n",
        "    print(f\"Rope Theta: {model_config.get('rope_theta')}\")\n",
        "    print(f\"Rope Interleaved: {model_config.get('rope_interleaved')}\")\n",
        "    print(f\"Rope Scaling: {model_config.get('rope_scaling')}\")\n",
        "    print(f\"Is LLaMA Config: {model_config.get('is_llama_config')}\")\n",
        "\n",
        "def main():\n",
        "    # Path to the JSON file\n",
        "    json_file_path = \"config_smollm2_135M.json\"\n",
        "\n",
        "    # Load the JSON file\n",
        "    try:\n",
        "        json_data = load_json(json_file_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load JSON file: {e}\")\n",
        "        return\n",
        "\n",
        "    # Extract the model configuration\n",
        "    model_config = json_data.get(\"model\", {}).get(\"model_config\", {})\n",
        "\n",
        "    # Print the model architecture\n",
        "    if model_config:\n",
        "        print_model_architecture(model_config)\n",
        "    else:\n",
        "        print(\"Error: Model configuration not found in the JSON file.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2SG554IbC-O",
        "outputId": "64387886-c4fd-46c2-ac05-7d3263d94875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Architecture:\n",
            "-------------------\n",
            "Hidden Size: 576\n",
            "Number of Hidden Layers: 30\n",
            "Number of Attention Heads: 9\n",
            "Number of Key-Value Heads: 3\n",
            "Intermediate Size: 1536\n",
            "Hidden Activation: silu\n",
            "Maximum Position Embeddings: 2048\n",
            "RMS Norm Epsilon: 1e-05\n",
            "Vocabulary Size: 49152\n",
            "Use Cache: True\n",
            "Tie Word Embeddings: True\n",
            "Initializer Range: 0.041666666666666664\n",
            "BOS Token ID: 0\n",
            "EOS Token ID: 0\n",
            "Pad Token ID: None\n",
            "Pretraining TP: 1\n",
            "Rope Theta: 10000.0\n",
            "Rope Interleaved: False\n",
            "Rope Scaling: None\n",
            "Is LLaMA Config: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from typing import Optional\n",
        "\n",
        "class RMSNorm(nn.Module):\n",
        "    \"\"\"\n",
        "    Root Mean Square Layer Normalization (RMSNorm).\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size: int, eps: float = 1e-5):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        variance = x.pow(2).mean(-1, keepdim=True)\n",
        "        x = x * torch.rsqrt(variance + self.eps)\n",
        "        return self.weight * x\n",
        "\n",
        "class RotaryPositionalEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    Rotary Positional Embedding (RoPE) for transformers.\n",
        "    \"\"\"\n",
        "    def __init__(self, dim: int, theta: float = 10000.0):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.theta = theta\n",
        "\n",
        "    def forward(self, x: torch.Tensor, seq_len: int) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Apply rotary positional embedding to the input tensor.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, seq_len, num_heads, head_dim).\n",
        "            seq_len (int): Sequence length.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor with rotary positional embeddings applied.\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, num_heads, head_dim = x.shape\n",
        "\n",
        "        # Generate position indices\n",
        "        position = torch.arange(seq_len, dtype=torch.float32, device=x.device).unsqueeze(-1)\n",
        "\n",
        "        # Generate frequencies\n",
        "        freqs = torch.exp(\n",
        "            torch.arange(0, head_dim, 2, dtype=torch.float32, device=x.device) * -(torch.log(torch.tensor(self.theta)) / head_dim)\n",
        "        )\n",
        "\n",
        "        # Compute sinusoids\n",
        "        sinusoid = position * freqs\n",
        "        sin = torch.sin(sinusoid)\n",
        "        cos = torch.cos(sinusoid)\n",
        "\n",
        "        # Reshape sin and cos to match the input tensor's shape\n",
        "        sin = sin.unsqueeze(0).unsqueeze(2)  # Shape: (1, seq_len, 1, head_dim // 2)\n",
        "        cos = cos.unsqueeze(0).unsqueeze(2)  # Shape: (1, seq_len, 1, head_dim // 2)\n",
        "\n",
        "        # Apply rotary embeddings\n",
        "        x_rotated = x.clone()\n",
        "        x_rotated[..., 0::2] = x[..., 0::2] * cos - x[..., 1::2] * sin\n",
        "        x_rotated[..., 1::2] = x[..., 1::2] * cos + x[..., 0::2] * sin\n",
        "\n",
        "        return x_rotated\n",
        "\n",
        "from torch.utils.checkpoint import checkpoint\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A single transformer block with self-attention and feed-forward layers.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size: int,\n",
        "        num_attention_heads: int,\n",
        "        intermediate_size: int,\n",
        "        num_key_value_heads: int,\n",
        "        rms_norm_eps: float,\n",
        "        hidden_act: str = \"silu\",\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.num_key_value_heads = num_key_value_heads\n",
        "        self.head_dim = hidden_size // num_attention_heads\n",
        "\n",
        "        # Ensure the hidden size is divisible by the number of attention heads\n",
        "        if hidden_size % num_attention_heads != 0:\n",
        "            raise ValueError(\n",
        "                f\"hidden_size ({hidden_size}) must be divisible by num_attention_heads ({num_attention_heads})\"\n",
        "            )\n",
        "\n",
        "        # Self-attention layers\n",
        "        self.q_proj = nn.Linear(hidden_size, hidden_size)\n",
        "        self.k_proj = nn.Linear(hidden_size, num_key_value_heads * self.head_dim)\n",
        "        self.v_proj = nn.Linear(hidden_size, num_key_value_heads * self.head_dim)\n",
        "        self.o_proj = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        # Feed-forward layers\n",
        "        self.gate_proj = nn.Linear(hidden_size, intermediate_size)\n",
        "        self.up_proj = nn.Linear(hidden_size, intermediate_size)\n",
        "        self.down_proj = nn.Linear(intermediate_size, hidden_size)\n",
        "\n",
        "        # Normalization layers\n",
        "        self.input_norm = RMSNorm(hidden_size, eps=rms_norm_eps)\n",
        "        self.post_attention_norm = RMSNorm(hidden_size, eps=rms_norm_eps)\n",
        "\n",
        "        # Activation function\n",
        "        self.act = nn.SiLU() if hidden_act == \"silu\" else nn.GELU()\n",
        "\n",
        "        # Rotary positional embedding\n",
        "        self.rope = RotaryPositionalEmbedding(self.head_dim)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        def create_custom_forward(module):\n",
        "            def custom_forward(*inputs):\n",
        "                return module._forward(inputs[0], inputs[1])\n",
        "            return custom_forward\n",
        "\n",
        "        # Use gradient checkpointing\n",
        "        return checkpoint(create_custom_forward(self), x, attention_mask)\n",
        "\n",
        "    def _forward(self, x: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        # Self-attention\n",
        "        residual = x\n",
        "        x = self.input_norm(x)\n",
        "\n",
        "        # Project inputs to query, key, and value\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "\n",
        "        # Reshape queries for multi-head attention\n",
        "        q = self.q_proj(x).view(batch_size, seq_len, self.num_attention_heads, self.head_dim)\n",
        "\n",
        "        # Reshape keys and values for key-value heads\n",
        "        k = self.k_proj(x).view(batch_size, seq_len, self.num_key_value_heads, self.head_dim)\n",
        "        v = self.v_proj(x).view(batch_size, seq_len, self.num_key_value_heads, self.head_dim)\n",
        "\n",
        "        # Apply rotary positional embedding\n",
        "        q = self.rope(q, seq_len)\n",
        "        k = self.rope(k, seq_len)\n",
        "\n",
        "        # Scaled dot-product attention\n",
        "        attn_output = F.scaled_dot_product_attention(q, k, v, attn_mask=attention_mask)\n",
        "        attn_output = attn_output.transpose(1, 2).reshape(batch_size, seq_len, self.hidden_size)\n",
        "        attn_output = self.o_proj(attn_output)\n",
        "\n",
        "        # Add residual connection\n",
        "        x = residual + attn_output\n",
        "\n",
        "        # Feed-forward network\n",
        "        residual = x\n",
        "        x = self.post_attention_norm(x)\n",
        "        gate = self.act(self.gate_proj(x))\n",
        "        up = self.up_proj(x)\n",
        "        ff_output = self.down_proj(gate * up)\n",
        "\n",
        "        # Add residual connection\n",
        "        x = residual + ff_output\n",
        "\n",
        "        return x\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    \"\"\"\n",
        "    The full transformer model with multiple layers.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size: int,\n",
        "        hidden_size: int,\n",
        "        num_hidden_layers: int,\n",
        "        num_attention_heads: int,\n",
        "        intermediate_size: int,\n",
        "        num_key_value_heads: int,\n",
        "        max_position_embeddings: int,\n",
        "        rms_norm_eps: float,\n",
        "        hidden_act: str = \"silu\",\n",
        "        tie_word_embeddings: bool = True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_hidden_layers = num_hidden_layers\n",
        "        self.max_position_embeddings = max_position_embeddings\n",
        "\n",
        "        # Embedding layers\n",
        "        self.embed_tokens = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.embed_positions = nn.Embedding(max_position_embeddings, hidden_size)\n",
        "\n",
        "        # Transformer blocks\n",
        "        self.layers = nn.ModuleList([\n",
        "            TransformerBlock(\n",
        "                hidden_size=hidden_size,\n",
        "                num_attention_heads=num_attention_heads,\n",
        "                intermediate_size=intermediate_size,\n",
        "                num_key_value_heads=num_key_value_heads,\n",
        "                rms_norm_eps=rms_norm_eps,\n",
        "                hidden_act=hidden_act,\n",
        "            )\n",
        "            for _ in range(num_hidden_layers)\n",
        "        ])\n",
        "\n",
        "        # Final normalization layer\n",
        "        self.final_norm = RMSNorm(hidden_size, eps=rms_norm_eps)\n",
        "\n",
        "        # Output layer (tied to input embeddings if specified)\n",
        "        self.lm_head = nn.Linear(hidden_size, vocab_size, bias=False)\n",
        "        if tie_word_embeddings:\n",
        "            self.lm_head.weight = self.embed_tokens.weight\n",
        "\n",
        "    def forward(self, input_ids: torch.Tensor, attention_mask: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
        "        # Embed tokens and positions\n",
        "        seq_len = input_ids.size(1)\n",
        "        position_ids = torch.arange(seq_len, dtype=torch.long, device=input_ids.device)\n",
        "        token_embeddings = self.embed_tokens(input_ids)\n",
        "        position_embeddings = self.embed_positions(position_ids)\n",
        "        x = token_embeddings + position_embeddings\n",
        "\n",
        "        # Pass through transformer layers\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, attention_mask)\n",
        "\n",
        "        # Final normalization\n",
        "        x = self.final_norm(x)\n",
        "\n",
        "        # Output logits\n",
        "        logits = self.lm_head(x)\n",
        "        return logits\n",
        "\n",
        "    def generate(\n",
        "        self,\n",
        "        input_ids: torch.Tensor,\n",
        "        max_length: int = 50,\n",
        "        temperature: float = 1.0,\n",
        "        top_k: int = 50,\n",
        "        do_sample: bool = True,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Generate text autoregressively.\n",
        "\n",
        "        Args:\n",
        "            input_ids (torch.Tensor): Input token IDs of shape (batch_size, seq_len).\n",
        "            max_length (int): Maximum length of the generated sequence.\n",
        "            temperature (float): Sampling temperature. Higher values mean more random sampling.\n",
        "            top_k (int): Top-k sampling. Only the top-k tokens are considered.\n",
        "            do_sample (bool): Whether to sample from the distribution or take the argmax.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Generated token IDs of shape (batch_size, max_length).\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            for _ in range(max_length - input_ids.size(1)):\n",
        "                # Get the logits for the last token\n",
        "                logits = self(input_ids)[:, -1, :]\n",
        "\n",
        "                # Apply temperature\n",
        "                logits = logits / temperature\n",
        "\n",
        "                # Top-k sampling\n",
        "                if top_k > 0:\n",
        "                    top_k_values, top_k_indices = torch.topk(logits, top_k)\n",
        "                    logits[logits < top_k_values[:, -1].unsqueeze(-1)] = -float(\"Inf\")\n",
        "\n",
        "                # Convert logits to probabilities\n",
        "                probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "                # Sample or take the argmax\n",
        "                if do_sample:\n",
        "                    next_token = torch.multinomial(probs, num_samples=1)\n",
        "                else:\n",
        "                    next_token = torch.argmax(probs, dim=-1, keepdim=True)\n",
        "\n",
        "                # Append the next token to the input_ids\n",
        "                input_ids = torch.cat([input_ids, next_token], dim=-1)\n",
        "\n",
        "        return input_ids\n",
        "\n",
        "# Create the model based on the configuration\n",
        "def create_model_from_config(config: dict) -> TransformerModel:\n",
        "    model_config = config[\"model\"][\"model_config\"]\n",
        "    return TransformerModel(\n",
        "        vocab_size=model_config[\"vocab_size\"],\n",
        "        hidden_size=model_config[\"hidden_size\"],\n",
        "        num_hidden_layers=model_config[\"num_hidden_layers\"],\n",
        "        num_attention_heads=model_config[\"num_attention_heads\"],\n",
        "        intermediate_size=model_config[\"intermediate_size\"],\n",
        "        num_key_value_heads=model_config[\"num_key_value_heads\"],\n",
        "        max_position_embeddings=model_config[\"max_position_embeddings\"],\n",
        "        rms_norm_eps=model_config[\"rms_norm_eps\"],\n",
        "        hidden_act=model_config[\"hidden_act\"],\n",
        "        tie_word_embeddings=model_config[\"tie_word_embeddings\"],\n",
        "    )\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    import json\n",
        "\n",
        "    # Load the configuration file\n",
        "    with open(\"config_smollm2_135M.json\", \"r\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    # Create the model\n",
        "    model = create_model_from_config(config)\n",
        "    print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOnlRBq5cfsy",
        "outputId": "c24dbdb0-4277-406c-e5c4-25056c18396d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerModel(\n",
            "  (embed_tokens): Embedding(49152, 576)\n",
            "  (embed_positions): Embedding(2048, 576)\n",
            "  (layers): ModuleList(\n",
            "    (0-29): 30 x TransformerBlock(\n",
            "      (q_proj): Linear(in_features=576, out_features=576, bias=True)\n",
            "      (k_proj): Linear(in_features=576, out_features=192, bias=True)\n",
            "      (v_proj): Linear(in_features=576, out_features=192, bias=True)\n",
            "      (o_proj): Linear(in_features=576, out_features=576, bias=True)\n",
            "      (gate_proj): Linear(in_features=576, out_features=1536, bias=True)\n",
            "      (up_proj): Linear(in_features=576, out_features=1536, bias=True)\n",
            "      (down_proj): Linear(in_features=1536, out_features=576, bias=True)\n",
            "      (input_norm): RMSNorm()\n",
            "      (post_attention_norm): RMSNorm()\n",
            "      (act): SiLU()\n",
            "      (rope): RotaryPositionalEmbedding()\n",
            "    )\n",
            "  )\n",
            "  (final_norm): RMSNorm()\n",
            "  (lm_head): Linear(in_features=576, out_features=49152, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer\n",
        "# from model import create_model_from_config\n",
        "import json\n",
        "import os\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "# Configuration\n",
        "CONFIG_FILE = \"config_smollm2_135M.json\"\n",
        "CHECKPOINT_DIR = \"checkpoints\"\n",
        "BATCH_SIZE = 4  # Reduced batch size\n",
        "SEQ_LENGTH = 1024  # Reduced sequence length\n",
        "GRADIENT_ACCUMULATION_STEPS = 1\n",
        "PREDICTION_INTERVAL = 500\n",
        "TRAIN_STEPS_PHASE_1 = 5000\n",
        "TRAIN_STEPS_PHASE_2 = 50\n",
        "\n",
        "# Load the configuration\n",
        "with open(CONFIG_FILE, \"r\") as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "# Set up the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(config[\"tokenizer\"][\"tokenizer_name_or_path\"])\n",
        "\n",
        "# Create the model\n",
        "model = create_model_from_config(config).to(device)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=config[\"optimizer\"][\"learning_rate_scheduler\"][\"learning_rate\"],\n",
        "    betas=(\n",
        "        config[\"optimizer\"][\"optimizer_factory\"][\"adam_beta1\"],\n",
        "        config[\"optimizer\"][\"optimizer_factory\"][\"adam_beta2\"],\n",
        "    ),\n",
        "    eps=config[\"optimizer\"][\"optimizer_factory\"][\"adam_eps\"],\n",
        "    weight_decay=config[\"optimizer\"][\"weight_decay\"],\n",
        ")\n",
        "\n",
        "# Define the loss function\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialize GradScaler for mixed precision\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, file_path, tokenizer, seq_length):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.seq_length = seq_length\n",
        "        with open(file_path, \"r\") as f:\n",
        "            self.text = f.read()\n",
        "        self.tokens = self.tokenizer.encode(self.text)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens) // self.seq_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start = idx * self.seq_length\n",
        "        end = start + self.seq_length\n",
        "        input_ids = self.tokens[start:end]\n",
        "        labels = self.tokens[start + 1 : end + 1]\n",
        "        return torch.tensor(input_ids, dtype=torch.long), torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "# Load the dataset\n",
        "dataset = TextDataset(\"input.txt\", tokenizer, SEQ_LENGTH)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Function to generate text\n",
        "def generate_text(model, tokenizer, prompt=\"\", max_length=50):\n",
        "    \"\"\"\n",
        "    Generate text using the model.\n",
        "\n",
        "    Args:\n",
        "        model (TransformerModel): The trained model.\n",
        "        tokenizer: The tokenizer used to encode/decode text.\n",
        "        prompt (str): The initial prompt for text generation.\n",
        "        max_length (int): Maximum length of the generated text.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text.\n",
        "    \"\"\"\n",
        "    # Encode the prompt\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Generate text\n",
        "    output_ids = model.generate(input_ids, max_length=max_length, do_sample=True)\n",
        "\n",
        "    # Decode the generated text\n",
        "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Training loop\n",
        "def train(initial_step=0, total_steps=5000, checkpoint_path=None):\n",
        "    model.train()\n",
        "    global_step = initial_step\n",
        "\n",
        "    # Load checkpoint if provided\n",
        "    if checkpoint_path:\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "        global_step = checkpoint[\"global_step\"]\n",
        "        print(f\"Loaded checkpoint from {checkpoint_path} at step {global_step}\")\n",
        "\n",
        "    while global_step < total_steps:\n",
        "        for batch_idx, (input_ids, labels) in enumerate(dataloader):\n",
        "            input_ids = input_ids.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass with mixed precision\n",
        "            with autocast():\n",
        "                outputs = model(input_ids)\n",
        "                loss = loss_fn(outputs.view(-1, outputs.size(-1)), labels.view(-1))\n",
        "\n",
        "            # Backward pass with gradient scaling\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # Gradient accumulation\n",
        "            if (batch_idx + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            # Logging\n",
        "            if global_step % 10 == 0:\n",
        "                print(f\"Step {global_step}, Loss: {loss.item()}\")\n",
        "\n",
        "            # Generate text every PREDICTION_INTERVAL steps\n",
        "            if global_step % PREDICTION_INTERVAL == 0:\n",
        "                generated_text = generate_text(model, tokenizer, prompt=\"Once upon a time\")\n",
        "                print(f\"Step {global_step}, Generated Text: {generated_text}\")\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "            # Stop after the specified number of training steps\n",
        "            if global_step >= total_steps:\n",
        "                break\n",
        "\n",
        "    # Save checkpoint at the end of training\n",
        "    checkpoint_path = os.path.join(CHECKPOINT_DIR, f\"checkpoint_{global_step}.pt\")\n",
        "    torch.save(\n",
        "        {\n",
        "            \"global_step\": global_step,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"loss\": loss.item(),\n",
        "        },\n",
        "        checkpoint_path,\n",
        "    )\n",
        "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
        "\n",
        "# Create the checkpoint directory if it doesn't exist\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# Phase 1: Train for 5000 steps\n",
        "print(\"Starting Phase 1: Training for 5000 steps\")\n",
        "train(initial_step=0, total_steps=TRAIN_STEPS_PHASE_1)\n",
        "\n",
        "# Phase 2: Load the checkpoint and train for 50 more steps\n",
        "print(\"Starting Phase 2: Loading checkpoint and training for 50 more steps\")\n",
        "checkpoint_path = os.path.join(CHECKPOINT_DIR, f\"checkpoint_{TRAIN_STEPS_PHASE_1}.pt\")\n",
        "train(initial_step=TRAIN_STEPS_PHASE_1, total_steps=TRAIN_STEPS_PHASE_1 + TRAIN_STEPS_PHASE_2, checkpoint_path=checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "svvatDgqgH29",
        "outputId": "06fd1c26-9334-45f0-d1a0-e709274890af"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-a0edd661c5de>:48: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Phase 1: Training for 5000 steps\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-a0edd661c5de>:115: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 0, Loss: 300.6046142578125\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0, Generated Text: Once upon a time time time time time time time time time time time time spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect spect\n",
            "Step 10, Loss: 79.6866455078125\n",
            "Step 20, Loss: 51.16653823852539\n",
            "Step 30, Loss: 44.327701568603516\n",
            "Step 40, Loss: 27.66715431213379\n",
            "Step 50, Loss: 20.721342086791992\n",
            "Step 60, Loss: 15.905719757080078\n",
            "Step 70, Loss: 11.343408584594727\n",
            "Step 80, Loss: 10.688121795654297\n",
            "Step 90, Loss: 9.59188461303711\n",
            "Step 100, Loss: 10.082836151123047\n",
            "Step 110, Loss: 10.10753345489502\n",
            "Step 120, Loss: 9.449414253234863\n",
            "Step 130, Loss: 8.042485237121582\n",
            "Step 140, Loss: 7.5388641357421875\n",
            "Step 150, Loss: 9.793695449829102\n",
            "Step 160, Loss: 9.59386920928955\n",
            "Step 170, Loss: 9.547626495361328\n",
            "Step 180, Loss: 9.427801132202148\n",
            "Step 190, Loss: 7.332798957824707\n",
            "Step 200, Loss: 8.496773719787598\n",
            "Step 210, Loss: 8.879924774169922\n",
            "Step 220, Loss: 8.73199462890625\n",
            "Step 230, Loss: 7.564198970794678\n",
            "Step 240, Loss: 7.07236385345459\n",
            "Step 250, Loss: 7.141294956207275\n",
            "Step 260, Loss: 7.21643590927124\n",
            "Step 270, Loss: 6.799673080444336\n",
            "Step 280, Loss: 7.627249240875244\n",
            "Step 290, Loss: 6.461006164550781\n",
            "Step 300, Loss: 6.430148124694824\n",
            "Step 310, Loss: 6.390108108520508\n",
            "Step 320, Loss: 6.389705657958984\n",
            "Step 330, Loss: 6.728174686431885\n",
            "Step 340, Loss: 5.940169811248779\n",
            "Step 350, Loss: 5.852295875549316\n",
            "Step 360, Loss: 6.173203945159912\n",
            "Step 370, Loss: 6.024510383605957\n",
            "Step 380, Loss: 6.0872955322265625\n",
            "Step 390, Loss: 6.091178894042969\n",
            "Step 400, Loss: 6.082760810852051\n",
            "Step 410, Loss: 5.315186023712158\n",
            "Step 420, Loss: 5.443442344665527\n",
            "Step 430, Loss: 5.360317707061768\n",
            "Step 440, Loss: 5.551982879638672\n",
            "Step 450, Loss: 5.655248165130615\n",
            "Step 460, Loss: 5.047664642333984\n",
            "Step 470, Loss: 5.281022548675537\n",
            "Step 480, Loss: 5.425401210784912\n",
            "Step 490, Loss: 5.335894584655762\n",
            "Step 500, Loss: 5.456624984741211\n",
            "Step 500, Generated Text: Once upon a time with us; for these, that?\n",
            "\n",
            "and that she never the king\n",
            "\n",
            "So for the pleasure;\n",
            "And here,\n",
            "And,\n",
            "\n",
            "And dost:\n",
            "The hand for your grace to the sits is\n",
            "Step 510, Loss: 4.805279731750488\n",
            "Step 520, Loss: 4.76432991027832\n",
            "Step 530, Loss: 5.336925506591797\n",
            "Step 540, Loss: 5.2957444190979\n",
            "Step 550, Loss: 4.895854473114014\n",
            "Step 560, Loss: 5.295706272125244\n",
            "Step 570, Loss: 4.997782230377197\n",
            "Step 580, Loss: 5.287980079650879\n",
            "Step 590, Loss: 4.438444137573242\n",
            "Step 600, Loss: 4.823502540588379\n",
            "Step 610, Loss: 5.047464370727539\n",
            "Step 620, Loss: 5.1298699378967285\n",
            "Step 630, Loss: 5.086873531341553\n",
            "Step 640, Loss: 5.057099342346191\n",
            "Step 650, Loss: 4.88533878326416\n",
            "Step 660, Loss: 4.917559623718262\n",
            "Step 670, Loss: 5.070035457611084\n",
            "Step 680, Loss: 4.906726360321045\n",
            "Step 690, Loss: 4.346901893615723\n",
            "Step 700, Loss: 4.751739025115967\n",
            "Step 710, Loss: 4.550561904907227\n",
            "Step 720, Loss: 4.781558513641357\n",
            "Step 730, Loss: 4.937236309051514\n",
            "Step 740, Loss: 5.000550746917725\n",
            "Step 750, Loss: 4.799488544464111\n",
            "Step 760, Loss: 4.360479831695557\n",
            "Step 770, Loss: 4.315971851348877\n",
            "Step 780, Loss: 4.465275764465332\n",
            "Step 790, Loss: 4.474040508270264\n",
            "Step 800, Loss: 4.835119724273682\n",
            "Step 810, Loss: 4.51313591003418\n",
            "Step 820, Loss: 4.54470682144165\n",
            "Step 830, Loss: 4.481934547424316\n",
            "Step 840, Loss: 4.012530326843262\n",
            "Step 850, Loss: 4.056670188903809\n",
            "Step 860, Loss: 4.2634735107421875\n",
            "Step 870, Loss: 4.437681198120117\n",
            "Step 880, Loss: 4.338399410247803\n",
            "Step 890, Loss: 4.248382091522217\n",
            "Step 900, Loss: 4.3386688232421875\n",
            "Step 910, Loss: 4.511900901794434\n",
            "Step 920, Loss: 4.364931583404541\n",
            "Step 930, Loss: 3.9296460151672363\n",
            "Step 940, Loss: 4.0923075675964355\n",
            "Step 950, Loss: 4.263650417327881\n",
            "Step 960, Loss: 4.340150833129883\n",
            "Step 970, Loss: 3.9459035396575928\n",
            "Step 980, Loss: 4.228902816772461\n",
            "Step 990, Loss: 4.228125095367432\n",
            "Step 1000, Loss: 4.246142864227295\n",
            "Step 1000, Generated Text: Once upon a time\n",
            "LEONTES:\n",
            "O:\n",
            "Tell him.\n",
            "\n",
            "\n",
            "But that he some truth, and hear you have\n",
            "To rue\n",
            "\n",
            "GLO:\n",
            "\n",
            "TRANIO:\n",
            "\n",
            "As you\n",
            "D\n",
            "Step 1010, Loss: 3.8599066734313965\n",
            "Step 1020, Loss: 4.121923446655273\n",
            "Step 1030, Loss: 4.0452470779418945\n",
            "Step 1040, Loss: 3.7068562507629395\n",
            "Step 1050, Loss: 3.849569082260132\n",
            "Step 1060, Loss: 4.025696277618408\n",
            "Step 1070, Loss: 4.083099365234375\n",
            "Step 1080, Loss: 4.692111492156982\n",
            "Step 1090, Loss: 4.318933486938477\n",
            "Step 1100, Loss: 3.8827433586120605\n",
            "Step 1110, Loss: 3.8969314098358154\n",
            "Step 1120, Loss: 3.924189329147339\n",
            "Step 1130, Loss: 4.156857490539551\n",
            "Step 1140, Loss: 3.952106475830078\n",
            "Step 1150, Loss: 3.9997684955596924\n",
            "Step 1160, Loss: 3.7808520793914795\n",
            "Step 1170, Loss: 3.9094250202178955\n",
            "Step 1180, Loss: 3.1824071407318115\n",
            "Step 1190, Loss: 3.5018739700317383\n",
            "Step 1200, Loss: 3.2513186931610107\n",
            "Step 1210, Loss: 3.8563671112060547\n",
            "Step 1220, Loss: 4.002571105957031\n",
            "Step 1230, Loss: 3.5869507789611816\n",
            "Step 1240, Loss: 3.6198549270629883\n",
            "Step 1250, Loss: 3.6540939807891846\n",
            "Step 1260, Loss: 3.4751226902008057\n",
            "Step 1270, Loss: 3.2120237350463867\n",
            "Step 1280, Loss: 3.27298641204834\n",
            "Step 1290, Loss: 3.208892345428467\n",
            "Step 1300, Loss: 3.593867301940918\n",
            "Step 1310, Loss: 3.5123069286346436\n",
            "Step 1320, Loss: 3.7796921730041504\n",
            "Step 1330, Loss: 3.821695327758789\n",
            "Step 1340, Loss: 3.729541540145874\n",
            "Step 1350, Loss: 3.1459131240844727\n",
            "Step 1360, Loss: 3.1122145652770996\n",
            "Step 1370, Loss: 3.314642906188965\n",
            "Step 1380, Loss: 3.1377851963043213\n",
            "Step 1390, Loss: 3.2868638038635254\n",
            "Step 1400, Loss: 3.6034722328186035\n",
            "Step 1410, Loss: 3.5551352500915527\n",
            "Step 1420, Loss: 4.05944299697876\n",
            "Step 1430, Loss: 3.204007625579834\n",
            "Step 1440, Loss: 3.478334903717041\n",
            "Step 1450, Loss: 3.2488625049591064\n",
            "Step 1460, Loss: 3.2807674407958984\n",
            "Step 1470, Loss: 3.002603530883789\n",
            "Step 1480, Loss: 3.32621693611145\n",
            "Step 1490, Loss: 3.503700017929077\n",
            "Step 1500, Loss: 3.391134738922119\n",
            "Step 1500, Generated Text: Once upon a time\n",
            "And the king, of.\n",
            "HENENENRY Bionalterheess them most humble-hearted of his account\n",
            "ROMEO: told their innocentut,\n",
            "How fa,\n",
            "As if you at tra\n",
            "Step 1510, Loss: 3.324604034423828\n",
            "Step 1520, Loss: 2.9112582206726074\n",
            "Step 1530, Loss: 3.0421712398529053\n",
            "Step 1540, Loss: 3.048382043838501\n",
            "Step 1550, Loss: 3.1103289127349854\n",
            "Step 1560, Loss: 2.954591751098633\n",
            "Step 1570, Loss: 3.0432345867156982\n",
            "Step 1580, Loss: 3.1295785903930664\n",
            "Step 1590, Loss: 3.2128121852874756\n",
            "Step 1600, Loss: 2.761688232421875\n",
            "Step 1610, Loss: 2.5363097190856934\n",
            "Step 1620, Loss: 3.03216552734375\n",
            "Step 1630, Loss: 3.163100242614746\n",
            "Step 1640, Loss: 3.5993595123291016\n",
            "Step 1650, Loss: 3.355926513671875\n",
            "Step 1660, Loss: 3.6913347244262695\n",
            "Step 1670, Loss: 3.61551570892334\n",
            "Step 1680, Loss: 3.2170019149780273\n",
            "Step 1690, Loss: 3.0724968910217285\n",
            "Step 1700, Loss: 2.853020191192627\n",
            "Step 1710, Loss: 2.803361654281616\n",
            "Step 1720, Loss: 2.6973156929016113\n",
            "Step 1730, Loss: 2.9268059730529785\n",
            "Step 1740, Loss: 2.80521297454834\n",
            "Step 1750, Loss: 2.8970494270324707\n",
            "Step 1760, Loss: 3.1316256523132324\n",
            "Step 1770, Loss: 2.2718868255615234\n",
            "Step 1780, Loss: 2.301581382751465\n",
            "Step 1790, Loss: 2.754795551300049\n",
            "Step 1800, Loss: 2.6956567764282227\n",
            "Step 1810, Loss: 2.797743320465088\n",
            "Step 1820, Loss: nan\n",
            "Step 1830, Loss: 3.0118257999420166\n",
            "Step 1840, Loss: 2.884500503540039\n",
            "Step 1850, Loss: 2.486931324005127\n",
            "Step 1860, Loss: 2.8528151512145996\n",
            "Step 1870, Loss: 2.783381700515747\n",
            "Step 1880, Loss: 4.12467622756958\n",
            "Step 1890, Loss: 4.528950214385986\n",
            "Step 1900, Loss: 5.34799337387085\n",
            "Step 1910, Loss: nan\n",
            "Step 1920, Loss: nan\n",
            "Step 1930, Loss: nan\n",
            "Step 1940, Loss: nan\n",
            "Step 1950, Loss: nan\n",
            "Step 1960, Loss: nan\n",
            "Step 1970, Loss: nan\n",
            "Step 1980, Loss: nan\n",
            "Step 1990, Loss: nan\n",
            "Step 2000, Loss: nan\n",
            "Step 2000, Generated Text: Once upon a time shall not as? what?\n",
            " me in to, do;\n",
            "\n",
            "\n",
            " to the dove have I be to the prison to the ne with from too,:\n",
            " as?\n",
            "But be't, in the spoil; I\n",
            "Step 2010, Loss: nan\n",
            "Step 2020, Loss: nan\n",
            "Step 2030, Loss: nan\n",
            "Step 2040, Loss: nan\n",
            "Step 2050, Loss: nan\n",
            "Step 2060, Loss: nan\n",
            "Step 2070, Loss: nan\n",
            "Step 2080, Loss: nan\n",
            "Step 2090, Loss: nan\n",
            "Step 2100, Loss: nan\n",
            "Step 2110, Loss: nan\n",
            "Step 2120, Loss: nan\n",
            "Step 2130, Loss: nan\n",
            "Step 2140, Loss: nan\n",
            "Step 2150, Loss: nan\n",
            "Step 2160, Loss: nan\n",
            "Step 2170, Loss: nan\n",
            "Step 2180, Loss: nan\n",
            "Step 2190, Loss: nan\n",
            "Step 2200, Loss: nan\n",
            "Step 2210, Loss: nan\n",
            "Step 2220, Loss: nan\n",
            "Step 2230, Loss: nan\n",
            "Step 2240, Loss: nan\n",
            "Step 2250, Loss: nan\n",
            "Step 2260, Loss: nan\n",
            "Step 2270, Loss: nan\n",
            "Step 2280, Loss: nan\n",
            "Step 2290, Loss: nan\n",
            "Step 2300, Loss: nan\n",
            "Step 2310, Loss: nan\n",
            "Step 2320, Loss: nan\n",
            "Step 2330, Loss: nan\n",
            "Step 2340, Loss: nan\n",
            "Step 2350, Loss: nan\n",
            "Step 2360, Loss: nan\n",
            "Step 2370, Loss: nan\n",
            "Step 2380, Loss: nan\n",
            "Step 2390, Loss: nan\n",
            "Step 2400, Loss: nan\n",
            "Step 2410, Loss: nan\n",
            "Step 2420, Loss: nan\n",
            "Step 2430, Loss: nan\n",
            "Step 2440, Loss: nan\n",
            "Step 2450, Loss: nan\n",
            "Step 2460, Loss: nan\n",
            "Step 2470, Loss: nan\n",
            "Step 2480, Loss: nan\n",
            "Step 2490, Loss: nan\n",
            "Step 2500, Loss: nan\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling cublasLtMatmul with transpose_mat1 1 transpose_mat2 0 m 1536 n 5 k 576 mat1_ld 576 mat2_ld 576 result_ld 1536 abcType 0 computeType 68 scaleType 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a0edd661c5de>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;31m# Phase 1: Train for 5000 steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting Phase 1: Training for 5000 steps\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRAIN_STEPS_PHASE_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;31m# Phase 2: Load the checkpoint and train for 50 more steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-a0edd661c5de>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(initial_step, total_steps, checkpoint_path)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Generate text every PREDICTION_INTERVAL steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mPREDICTION_INTERVAL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mgenerated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Once upon a time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Step {global_step}, Generated Text: {generated_text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-a0edd661c5de>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(model, tokenizer, prompt, max_length)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;31m# Generate text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0moutput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# Decode the generated text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b7135fc9b21f>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, temperature, top_k, do_sample)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0;31m# Get the logits for the last token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;31m# Apply temperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b7135fc9b21f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Pass through transformer layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Final normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b7135fc9b21f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attention_mask)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# Use gradient checkpointing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_custom_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py\u001b[0m in \u001b[0;36mcheckpoint\u001b[0;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0;34m\"use_reentrant=False.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             )\n\u001b[0;32m--> 489\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         gen = _checkpoint_without_reentrant_generator(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# See NOTE: [functorch vjp and autograd interaction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap_dead_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_setup_ctx_defined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b7135fc9b21f>\u001b[0m in \u001b[0;36mcustom_forward\u001b[0;34m(*inputs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcreate_custom_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mcustom_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b7135fc9b21f>\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x, attention_mask)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mff_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_EXECUTION_FAILED when calling cublasLtMatmul with transpose_mat1 1 transpose_mat2 0 m 1536 n 5 k 576 mat1_ld 576 mat2_ld 576 result_ld 1536 abcType 0 computeType 68 scaleType 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer\n",
        "# from model import create_model_from_config\n",
        "import json\n",
        "import os\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "# Configuration\n",
        "CONFIG_FILE = \"config_smollm2_135M.json\"\n",
        "CHECKPOINT_DIR = \"checkpoints\"\n",
        "BATCH_SIZE = 2  # Further reduced batch size\n",
        "SEQ_LENGTH = 512  # Further reduced sequence length\n",
        "GRADIENT_ACCUMULATION_STEPS = 1\n",
        "PREDICTION_INTERVAL = 500\n",
        "TRAIN_STEPS_PHASE_1 = 5000\n",
        "TRAIN_STEPS_PHASE_2 = 50\n",
        "\n",
        "# Load the configuration\n",
        "with open(CONFIG_FILE, \"r\") as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "# Set up the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(config[\"tokenizer\"][\"tokenizer_name_or_path\"])\n",
        "print(\"Tokenizer vocab size:\", tokenizer.vocab_size)\n",
        "print(\"Model vocab size:\", config[\"model\"][\"model_config\"][\"vocab_size\"])\n",
        "\n",
        "# Ensure tokenizer vocab size matches model vocab size\n",
        "assert tokenizer.vocab_size == config[\"model\"][\"model_config\"][\"vocab_size\"], \"Tokenizer vocab size does not match model vocab size\"\n",
        "\n",
        "# Add pad_token_id to model config if missing\n",
        "if \"pad_token_id\" not in config[\"model\"][\"model_config\"]:\n",
        "    config[\"model\"][\"model_config\"][\"pad_token_id\"] = tokenizer.pad_token_id\n",
        "\n",
        "# Create the model\n",
        "model = create_model_from_config(config).to(device)\n",
        "\n",
        "# Define the optimizer with a lower learning rate\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=1e-4,  # Reduced learning rate\n",
        "    betas=(\n",
        "        config[\"optimizer\"][\"optimizer_factory\"][\"adam_beta1\"],\n",
        "        config[\"optimizer\"][\"optimizer_factory\"][\"adam_beta2\"],\n",
        "    ),\n",
        "    eps=config[\"optimizer\"][\"optimizer_factory\"][\"adam_eps\"],\n",
        "    weight_decay=config[\"optimizer\"][\"weight_decay\"],\n",
        ")\n",
        "\n",
        "# Define the loss function\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialize GradScaler for mixed precision\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, file_path, tokenizer, seq_length):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.seq_length = seq_length\n",
        "        with open(file_path, \"r\") as f:\n",
        "            self.text = f.read()\n",
        "        self.tokens = self.tokenizer.encode(self.text)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens) // self.seq_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start = idx * self.seq_length\n",
        "        end = start + self.seq_length\n",
        "        input_ids = self.tokens[start:end]\n",
        "        labels = self.tokens[start + 1 : end + 1]\n",
        "        return torch.tensor(input_ids, dtype=torch.long), torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "# Load the dataset\n",
        "dataset = TextDataset(\"input.txt\", tokenizer, SEQ_LENGTH)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Function to generate text\n",
        "def generate_text(model, tokenizer, prompt=\"\", max_length=50):\n",
        "    \"\"\"\n",
        "    Generate text using the model.\n",
        "\n",
        "    Args:\n",
        "        model (TransformerModel): The trained model.\n",
        "        tokenizer: The tokenizer used to encode/decode text.\n",
        "        prompt (str): The initial prompt for text generation.\n",
        "        max_length (int): Maximum length of the generated text.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text.\n",
        "    \"\"\"\n",
        "    # Encode the prompt\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Generate text\n",
        "    output_ids = model.generate(input_ids, max_length=max_length, do_sample=True)\n",
        "\n",
        "    # Decode the generated text\n",
        "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Training loop\n",
        "def train(initial_step=0, total_steps=5000, checkpoint_path=None):\n",
        "    model.train()\n",
        "    global_step = initial_step\n",
        "\n",
        "    # Load checkpoint if provided\n",
        "    if checkpoint_path:\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "        global_step = checkpoint[\"global_step\"]\n",
        "        print(f\"Loaded checkpoint from {checkpoint_path} at step {global_step}\")\n",
        "\n",
        "    while global_step < total_steps:\n",
        "        for batch_idx, (input_ids, labels) in enumerate(dataloader):\n",
        "            input_ids = input_ids.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Debugging: Check token IDs\n",
        "            if torch.any(input_ids < 0) or torch.any(input_ids >= model.vocab_size):\n",
        "                raise ValueError(f\"Invalid token IDs detected: {input_ids}\")\n",
        "\n",
        "            # Debugging: Check shapes\n",
        "            assert input_ids.shape == labels.shape, \"Mismatched shapes between input_ids and labels\"\n",
        "\n",
        "            # Forward pass with mixed precision\n",
        "            with autocast():\n",
        "                outputs = model(input_ids)\n",
        "                loss = loss_fn(outputs.view(-1, outputs.size(-1)), labels.view(-1))\n",
        "\n",
        "            # Check for nan or inf in loss\n",
        "            if torch.isnan(loss).any() or torch.isinf(loss).any():\n",
        "                print(\"Loss is nan or inf. Stopping training.\")\n",
        "                return\n",
        "\n",
        "            # Backward pass with gradient scaling\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            # Gradient accumulation\n",
        "            if (batch_idx + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            # Logging\n",
        "            if global_step % 10 == 0:\n",
        "                print(f\"Step {global_step}, Loss: {loss.item()}\")\n",
        "\n",
        "            # Generate text every PREDICTION_INTERVAL steps\n",
        "            if global_step % PREDICTION_INTERVAL == 0:\n",
        "                generated_text = generate_text(model, tokenizer, prompt=\"Once upon a time\")\n",
        "                print(f\"Step {global_step}, Generated Text: {generated_text}\")\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "            # Stop after the specified number of training steps\n",
        "            if global_step >= total_steps:\n",
        "                break\n",
        "\n",
        "    # Save checkpoint at the end of training\n",
        "    checkpoint_path = os.path.join(CHECKPOINT_DIR, f\"checkpoint_{global_step}.pt\")\n",
        "    torch.save(\n",
        "        {\n",
        "            \"global_step\": global_step,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"loss\": loss.item(),\n",
        "        },\n",
        "        checkpoint_path,\n",
        "    )\n",
        "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
        "\n",
        "# Create the checkpoint directory if it doesn't exist\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# Phase 1: Train for 5000 steps\n",
        "print(\"Starting Phase 1: Training for 5000 steps\")\n",
        "train(initial_step=0, total_steps=TRAIN_STEPS_PHASE_1)\n",
        "\n",
        "# Phase 2: Load the checkpoint and train for 50 more steps\n",
        "print(\"Starting Phase 2: Loading checkpoint and training for 50 more steps\")\n",
        "checkpoint_path = os.path.join(CHECKPOINT_DIR, f\"checkpoint_{TRAIN_STEPS_PHASE_1}.pt\")\n",
        "train(initial_step=TRAIN_STEPS_PHASE_1, total_steps=TRAIN_STEPS_PHASE_1 + TRAIN_STEPS_PHASE_2, checkpoint_path=checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0f665f5d3e9d47dabaa802647a9ef435",
            "d46187c0f2954e499d89d2743815010e",
            "903db8a472664999913db44119b000e9",
            "4f9fa6e9208c4518b08012efede44522",
            "3a45fb902b9942a9976f8c67ace7ae2f",
            "70515edeb9ff4af795d5ee69f2fb1c7b",
            "008b50359b34498b804e64d074102f91",
            "10215db5e2db40f6a4547efe7f2fb648",
            "df7ba48fc3e1407a9b85d9f38c237892",
            "97147c86f09e4547b5cfe07c123faded",
            "7fa67b532e184734b80975f53ea63266",
            "507a674781eb4bfa9cdc6cda9f3af6af",
            "f351a47a278e402881de67bea29aa02f",
            "dc8134ec3932469eb58286f553f611bb",
            "581668bfd46644109124c4a27c9b0791",
            "9ebf09c98cd54d55a657e930bb928fa5",
            "73d4a7e75e7348a68223bd77ee24b284",
            "3b65e1357cd94cdc985af1694d478617",
            "b35a98258c2e42e184f6df86d7b9b572",
            "82ef2da7cf6d489cbab5c0dcb89e174c",
            "f829ef77e8ed470bab2baae34cc23029",
            "27b40a09398c401c8faa9e013c3dd370",
            "188f8700a2d14c5d86ebb2fc14e5f381",
            "8dc3621ceed64e10909c4a5411b645f5",
            "183b9739e4824d649b2a92d3c137300a",
            "f7521f480b7d4e098cb4fbc7b4fb8bab",
            "749793d153364a65bfb3aa1dbd497310",
            "113b6a37c2ab48f78024b4f2beb449aa",
            "990d16be91844a988e0d3a2bb4c3832d",
            "77580489b25340949b82a71fc4eca1cd",
            "d9fa659945924c41b16b3406ac948a72",
            "5687904ed79a4b3eb65fc5ced5f0d0a1",
            "1056cc7088114047be0f170dc491b9eb",
            "3c242f97209a4a8f8beabd10d209ee30",
            "77e911d7f0b0426781353b20481425a3",
            "87765b5ec39e4389b61a4166d30fd31a",
            "12c966f1ecd74a558e79168f288f1e22",
            "680843c588894e75905036eb9c837dfb",
            "55d0ce3331b945f285d2aa0eb020779f",
            "43a89cc08446414ab18b88e048392cd9",
            "776c19f02c834463a041f3077660ee09",
            "dc98de438fb04d6da1b26b00f7f5da7f",
            "0d9b43a8b4c34d2cbc596976593cc3da",
            "d83cd8d496054470a67f0e3107006a24",
            "7ec2186446e74863afac48eda94bca9d",
            "46b5d453d2ed4fe5a799bc4d4c0bda08",
            "14fd2233c0e3457eb03063ffb00c2513",
            "238ca8ebb3e64db29bf8173c985c0bd2",
            "4462a3b5eff746f3bd3b49a534f363b9",
            "e5e8f139532142f2982b0cec20717b1f",
            "01e241c1257b4020b4354d80e93316a5",
            "3fa33c9fd83c4a60b4fbf7e091f8d6e3",
            "3958f9a214104f81bce5cfebecc2bc1c",
            "0d8b2878b7a441098ec9711a926a056c",
            "da7485aa6cb04ace8922111c8047617b"
          ]
        },
        "id": "VsTNZB4o3K0x",
        "outputId": "52ee3a0f-742e-4ce0-ac4c-b2a4a3424df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.91k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f665f5d3e9d47dabaa802647a9ef435"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "507a674781eb4bfa9cdc6cda9f3af6af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "188f8700a2d14c5d86ebb2fc14e5f381"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c242f97209a4a8f8beabd10d209ee30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/489 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ec2186446e74863afac48eda94bca9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer vocab size: 49152\n",
            "Model vocab size: 49152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-26cbe3f04d50>:57: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Phase 1: Training for 5000 steps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-26cbe3f04d50>:131: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0, Loss: 298.673095703125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0, Generated Text: Once upon a time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time\n",
            "Step 10, Loss: 161.7198028564453\n",
            "Step 20, Loss: 53.27239227294922\n",
            "Step 30, Loss: 48.80675506591797\n",
            "Step 40, Loss: 40.90314483642578\n",
            "Step 50, Loss: 36.19815444946289\n",
            "Step 60, Loss: 39.507850646972656\n",
            "Step 70, Loss: 34.20205307006836\n",
            "Step 80, Loss: 33.852439880371094\n",
            "Step 90, Loss: 32.16545104980469\n",
            "Step 100, Loss: 29.291702270507812\n",
            "Step 110, Loss: 29.522321701049805\n",
            "Step 120, Loss: 29.088640213012695\n",
            "Step 130, Loss: 27.521713256835938\n",
            "Step 140, Loss: 24.323755264282227\n",
            "Step 150, Loss: 26.249013900756836\n",
            "Step 160, Loss: 26.47113609313965\n",
            "Step 170, Loss: 25.80221939086914\n",
            "Step 180, Loss: 26.118669509887695\n",
            "Step 190, Loss: 26.004623413085938\n",
            "Step 200, Loss: 24.777692794799805\n",
            "Step 210, Loss: 24.28512954711914\n",
            "Step 220, Loss: 24.681190490722656\n",
            "Step 230, Loss: 24.10757827758789\n",
            "Step 240, Loss: 21.66363525390625\n",
            "Step 250, Loss: 20.54287338256836\n",
            "Step 260, Loss: 22.41187286376953\n",
            "Step 270, Loss: 23.472471237182617\n",
            "Step 280, Loss: 21.981117248535156\n",
            "Step 290, Loss: 23.44472312927246\n",
            "Step 300, Loss: 20.112539291381836\n",
            "Step 310, Loss: 23.37647247314453\n",
            "Step 320, Loss: 22.089183807373047\n",
            "Step 330, Loss: 20.25001335144043\n",
            "Step 340, Loss: 18.61956214904785\n",
            "Step 350, Loss: 18.933059692382812\n",
            "Step 360, Loss: 18.674894332885742\n",
            "Step 370, Loss: 17.993762969970703\n",
            "Step 380, Loss: 19.639123916625977\n",
            "Step 390, Loss: 17.674570083618164\n",
            "Step 400, Loss: 16.80828094482422\n",
            "Step 410, Loss: 17.181320190429688\n",
            "Step 420, Loss: 16.946876525878906\n",
            "Step 430, Loss: 17.83005714416504\n",
            "Step 440, Loss: 15.651033401489258\n",
            "Step 450, Loss: 18.454517364501953\n",
            "Step 460, Loss: 16.63481330871582\n",
            "Step 470, Loss: 15.648175239562988\n",
            "Step 480, Loss: 16.56731414794922\n",
            "Step 490, Loss: 17.62734603881836\n",
            "Step 500, Loss: 14.438735961914062\n",
            "Step 500, Generated Text: Once upon a time.\n",
            " chimney Siege Siege Siege Siege me with he will I amroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopyroscopy\n",
            "Step 510, Loss: 14.176923751831055\n",
            "Step 520, Loss: 15.889780044555664\n",
            "Step 530, Loss: 15.74270248413086\n",
            "Step 540, Loss: 15.329530715942383\n",
            "Step 550, Loss: 14.359466552734375\n",
            "Step 560, Loss: 12.870942115783691\n",
            "Step 570, Loss: 15.497179985046387\n",
            "Step 580, Loss: 12.986872673034668\n",
            "Step 590, Loss: 15.488107681274414\n",
            "Step 600, Loss: 13.503036499023438\n",
            "Step 610, Loss: 15.491958618164062\n",
            "Step 620, Loss: 13.854405403137207\n",
            "Step 630, Loss: 14.208255767822266\n",
            "Step 640, Loss: 13.129327774047852\n",
            "Step 650, Loss: 13.03030014038086\n",
            "Step 660, Loss: 11.245790481567383\n",
            "Step 670, Loss: 13.164412498474121\n",
            "Step 680, Loss: 11.540695190429688\n",
            "Step 690, Loss: 12.1759672164917\n",
            "Step 700, Loss: 10.381786346435547\n",
            "Step 710, Loss: 12.44844913482666\n",
            "Step 720, Loss: 12.392511367797852\n",
            "Step 730, Loss: 12.051837921142578\n",
            "Step 740, Loss: 10.566213607788086\n",
            "Step 750, Loss: 12.038056373596191\n",
            "Step 760, Loss: 10.757365226745605\n",
            "Step 770, Loss: 8.77734088897705\n",
            "Step 780, Loss: 11.901004791259766\n",
            "Step 790, Loss: 9.17380428314209\n",
            "Step 800, Loss: 11.347450256347656\n",
            "Step 810, Loss: 10.206623077392578\n",
            "Step 820, Loss: 11.450851440429688\n",
            "Step 830, Loss: 12.814352035522461\n",
            "Step 840, Loss: 9.982460021972656\n",
            "Step 850, Loss: 11.11577033996582\n",
            "Step 860, Loss: 9.512829780578613\n",
            "Step 870, Loss: 11.719647407531738\n",
            "Step 880, Loss: 10.618824005126953\n",
            "Step 890, Loss: 11.457428932189941\n",
            "Step 900, Loss: 10.632832527160645\n",
            "Step 910, Loss: 10.035784721374512\n",
            "Step 920, Loss: 9.726757049560547\n",
            "Step 930, Loss: 9.692160606384277\n",
            "Step 940, Loss: 10.293136596679688\n",
            "Step 950, Loss: 10.009588241577148\n",
            "Step 960, Loss: 8.913101196289062\n",
            "Step 970, Loss: 8.751760482788086\n",
            "Step 980, Loss: 9.305010795593262\n",
            "Step 990, Loss: 9.198732376098633\n",
            "Step 1000, Loss: 10.3203125\n",
            "Step 1000, Generated Text: Once upon a time,\n",
            "Hath with dismiss with\n",
            "Second house of your most it in the gates of a thing of those\n",
            "JULET:\n",
            "That it?\n",
            "\n",
            " hands;\n",
            "And could you,\n",
            "That is it have not\n",
            "Step 1010, Loss: 8.767914772033691\n",
            "Step 1020, Loss: 8.724315643310547\n",
            "Step 1030, Loss: 8.2445068359375\n",
            "Step 1040, Loss: 8.739141464233398\n",
            "Step 1050, Loss: 9.232388496398926\n",
            "Step 1060, Loss: 10.012842178344727\n",
            "Step 1070, Loss: 8.328546524047852\n",
            "Step 1080, Loss: 9.481658935546875\n",
            "Step 1090, Loss: 8.167487144470215\n",
            "Step 1100, Loss: 7.380870342254639\n",
            "Step 1110, Loss: 9.35218620300293\n",
            "Step 1120, Loss: 7.560133934020996\n",
            "Step 1130, Loss: 8.60551929473877\n",
            "Step 1140, Loss: 6.332787036895752\n",
            "Step 1150, Loss: 9.595399856567383\n",
            "Step 1160, Loss: 8.035542488098145\n",
            "Step 1170, Loss: 8.077582359313965\n",
            "Step 1180, Loss: 8.248197555541992\n",
            "Step 1190, Loss: 8.059468269348145\n",
            "Step 1200, Loss: 7.7832136154174805\n",
            "Step 1210, Loss: 8.14351749420166\n",
            "Step 1220, Loss: 8.623682022094727\n",
            "Step 1230, Loss: 8.146284103393555\n",
            "Step 1240, Loss: 6.687222957611084\n",
            "Step 1250, Loss: 8.448029518127441\n",
            "Step 1260, Loss: 8.627630233764648\n",
            "Step 1270, Loss: 7.296268463134766\n",
            "Step 1280, Loss: 8.317839622497559\n",
            "Step 1290, Loss: 7.831668853759766\n",
            "Step 1300, Loss: 8.318962097167969\n",
            "Step 1310, Loss: 6.133232593536377\n",
            "Step 1320, Loss: 7.32300329208374\n",
            "Step 1330, Loss: 6.4591569900512695\n",
            "Step 1340, Loss: 6.587627410888672\n",
            "Step 1350, Loss: 6.743601322174072\n",
            "Step 1360, Loss: 6.560209274291992\n",
            "Step 1370, Loss: 5.610414505004883\n",
            "Step 1380, Loss: 7.434392929077148\n",
            "Step 1390, Loss: 6.472136497497559\n",
            "Step 1400, Loss: 6.951707363128662\n",
            "Step 1410, Loss: 6.643671035766602\n",
            "Step 1420, Loss: 6.483028411865234\n",
            "Step 1430, Loss: 7.996747970581055\n",
            "Step 1440, Loss: 7.316842079162598\n",
            "Step 1450, Loss: 6.028120994567871\n",
            "Step 1460, Loss: 7.318983554840088\n",
            "Step 1470, Loss: 6.991118907928467\n",
            "Step 1480, Loss: 6.735762119293213\n",
            "Step 1490, Loss: 6.588406562805176\n",
            "Step 1500, Loss: 6.223276138305664\n",
            "Step 1500, Generated Text: Once upon a time of love, my husband and that I do it may be the shall a man that I him, have you not just,\n",
            "To truth truth.\n",
            "Than, sir?\n",
            "Nay, that\n",
            "\n",
            "\n",
            "SIC\n",
            "Step 1510, Loss: 7.062294960021973\n",
            "Step 1520, Loss: 6.751976490020752\n",
            "Step 1530, Loss: 7.663725852966309\n",
            "Step 1540, Loss: 5.642483711242676\n",
            "Step 1550, Loss: 6.144152641296387\n",
            "Step 1560, Loss: 7.291452884674072\n",
            "Step 1570, Loss: 6.32621431350708\n",
            "Step 1580, Loss: 6.069746017456055\n",
            "Step 1590, Loss: 6.902225494384766\n",
            "Step 1600, Loss: 6.112851142883301\n",
            "Step 1610, Loss: 6.849734783172607\n",
            "Step 1620, Loss: 6.4091644287109375\n",
            "Step 1630, Loss: 6.797758102416992\n",
            "Step 1640, Loss: 6.954246997833252\n",
            "Step 1650, Loss: 5.962377548217773\n",
            "Step 1660, Loss: 5.960846900939941\n",
            "Step 1670, Loss: 7.15975284576416\n",
            "Step 1680, Loss: 5.342291355133057\n",
            "Step 1690, Loss: 6.048342227935791\n",
            "Step 1700, Loss: 6.155762195587158\n",
            "Step 1710, Loss: 5.789492607116699\n",
            "Step 1720, Loss: 5.773763179779053\n",
            "Step 1730, Loss: 5.557508945465088\n",
            "Step 1740, Loss: 6.197876930236816\n",
            "Step 1750, Loss: 5.617112636566162\n",
            "Step 1760, Loss: 4.887497901916504\n",
            "Step 1770, Loss: 4.669433116912842\n",
            "Step 1780, Loss: 5.502862453460693\n",
            "Step 1790, Loss: 5.4518141746521\n",
            "Step 1800, Loss: 6.015498638153076\n",
            "Step 1810, Loss: 5.932127952575684\n",
            "Step 1820, Loss: 5.017769813537598\n",
            "Step 1830, Loss: 5.718806266784668\n",
            "Step 1840, Loss: 5.5754780769348145\n",
            "Step 1850, Loss: 5.107176780700684\n",
            "Step 1860, Loss: 5.8231306076049805\n",
            "Step 1870, Loss: 4.714074611663818\n",
            "Step 1880, Loss: 5.415058135986328\n",
            "Step 1890, Loss: 5.639251232147217\n",
            "Step 1900, Loss: 5.104860305786133\n",
            "Step 1910, Loss: 5.736206531524658\n",
            "Step 1920, Loss: 5.395174980163574\n",
            "Step 1930, Loss: 5.489696025848389\n",
            "Step 1940, Loss: 5.212561130523682\n",
            "Step 1950, Loss: 4.503634452819824\n",
            "Step 1960, Loss: 6.316047191619873\n",
            "Step 1970, Loss: 5.03087043762207\n",
            "Step 1980, Loss: 5.321755409240723\n",
            "Step 1990, Loss: 4.978254795074463\n",
            "Step 2000, Loss: 3.148458480834961\n",
            "Step 2000, Generated Text: Once upon a time I were were a house and I am I do\n",
            " serve choler:\n",
            "\n",
            "\n",
            "You do fear to her grave to bed.\n",
            "We can'd you in so, none but his power? hold of joy I'll tell\n",
            "Step 2010, Loss: 4.8854079246521\n",
            "Step 2020, Loss: 4.33787727355957\n",
            "Step 2030, Loss: 4.273275852203369\n",
            "Step 2040, Loss: 4.703315258026123\n",
            "Step 2050, Loss: 4.559462547302246\n",
            "Step 2060, Loss: 4.871768474578857\n",
            "Step 2070, Loss: 4.205741882324219\n",
            "Step 2080, Loss: 4.938837051391602\n",
            "Step 2090, Loss: 4.592440605163574\n",
            "Step 2100, Loss: 4.697325229644775\n",
            "Step 2110, Loss: 4.56931734085083\n",
            "Step 2120, Loss: 4.163435935974121\n",
            "Step 2130, Loss: 4.337307929992676\n",
            "Step 2140, Loss: 3.6652283668518066\n",
            "Step 2150, Loss: 4.368828296661377\n",
            "Step 2160, Loss: 4.337865352630615\n",
            "Step 2170, Loss: 5.565960884094238\n",
            "Step 2180, Loss: 5.433318614959717\n",
            "Step 2190, Loss: 5.081711292266846\n",
            "Step 2200, Loss: 3.3119425773620605\n",
            "Step 2210, Loss: 4.22356653213501\n",
            "Step 2220, Loss: 4.607606887817383\n",
            "Step 2230, Loss: 3.860258102416992\n",
            "Step 2240, Loss: 5.206418991088867\n",
            "Step 2250, Loss: 3.9129555225372314\n",
            "Step 2260, Loss: 4.362051486968994\n",
            "Step 2270, Loss: 4.353427410125732\n",
            "Step 2280, Loss: 4.5223388671875\n",
            "Step 2290, Loss: 3.2783524990081787\n",
            "Step 2300, Loss: 4.993286609649658\n",
            "Step 2310, Loss: 5.610108852386475\n",
            "Step 2320, Loss: 4.816854953765869\n",
            "Step 2330, Loss: 4.401554107666016\n",
            "Step 2340, Loss: 2.628469228744507\n",
            "Step 2350, Loss: 2.7710671424865723\n",
            "Step 2360, Loss: 2.668362855911255\n",
            "Step 2370, Loss: 4.256646633148193\n",
            "Step 2380, Loss: 2.8790197372436523\n",
            "Step 2390, Loss: 3.1212406158447266\n",
            "Step 2400, Loss: 2.5945451259613037\n",
            "Step 2410, Loss: 3.086362600326538\n",
            "Step 2420, Loss: 2.4941959381103516\n",
            "Step 2430, Loss: 3.2463769912719727\n",
            "Step 2440, Loss: 2.422731876373291\n",
            "Step 2450, Loss: 3.612307548522949\n",
            "Step 2460, Loss: 2.7401492595672607\n",
            "Step 2470, Loss: 3.2063918113708496\n",
            "Step 2480, Loss: 2.9105722904205322\n",
            "Step 2490, Loss: 2.7961478233337402\n",
            "Step 2500, Loss: 2.3211355209350586\n",
            "Step 2500, Generated Text: Once upon a time by his ch chinius\n",
            "Myour of fall. I pity; am not a-morrow, his soul, and break ourmsey,\n",
            "\n",
            "Messenger:\n",
            "\n",
            "ISABHear it it.\n",
            "\n",
            "Step 2510, Loss: 2.7288599014282227\n",
            "Step 2520, Loss: 3.075627326965332\n",
            "Step 2530, Loss: 2.3801233768463135\n",
            "Step 2540, Loss: 2.5008256435394287\n",
            "Step 2550, Loss: 2.6280159950256348\n",
            "Step 2560, Loss: 3.1630353927612305\n",
            "Step 2570, Loss: 3.2319815158843994\n",
            "Step 2580, Loss: 2.764860153198242\n",
            "Step 2590, Loss: 3.1888012886047363\n",
            "Step 2600, Loss: 3.63502836227417\n",
            "Step 2610, Loss: 2.6919901371002197\n",
            "Step 2620, Loss: 2.848949432373047\n",
            "Step 2630, Loss: 3.2230420112609863\n",
            "Step 2640, Loss: 2.5378286838531494\n",
            "Step 2650, Loss: 3.2283198833465576\n",
            "Step 2660, Loss: 3.762216567993164\n",
            "Step 2670, Loss: 1.1403989791870117\n",
            "Step 2680, Loss: 1.4753514528274536\n",
            "Step 2690, Loss: 1.2980839014053345\n",
            "Step 2700, Loss: 1.5468569993972778\n",
            "Step 2710, Loss: 1.7796961069107056\n",
            "Step 2720, Loss: 1.4584238529205322\n",
            "Step 2730, Loss: 1.057477355003357\n",
            "Step 2740, Loss: 1.4592095613479614\n",
            "Step 2750, Loss: 1.1333478689193726\n",
            "Step 2760, Loss: 1.796793818473816\n",
            "Step 2770, Loss: 1.644709825515747\n",
            "Step 2780, Loss: 1.7063744068145752\n",
            "Step 2790, Loss: 1.1915030479431152\n",
            "Step 2800, Loss: 1.5953346490859985\n",
            "Step 2810, Loss: 1.1435478925704956\n",
            "Step 2820, Loss: 1.4130792617797852\n",
            "Step 2830, Loss: 1.888588309288025\n",
            "Step 2840, Loss: 1.8576711416244507\n",
            "Step 2850, Loss: 1.9564307928085327\n",
            "Step 2860, Loss: 1.3911230564117432\n",
            "Step 2870, Loss: 1.5527881383895874\n",
            "Step 2880, Loss: 1.5229054689407349\n",
            "Step 2890, Loss: 1.5248662233352661\n",
            "Step 2900, Loss: 1.8154019117355347\n",
            "Step 2910, Loss: 1.3174216747283936\n",
            "Step 2920, Loss: 1.6598738431930542\n",
            "Step 2930, Loss: 1.9544072151184082\n",
            "Step 2940, Loss: 1.7167913913726807\n",
            "Step 2950, Loss: 1.3648496866226196\n",
            "Step 2960, Loss: 1.2155450582504272\n",
            "Step 2970, Loss: 1.3811464309692383\n",
            "Step 2980, Loss: 2.0502068996429443\n",
            "Step 2990, Loss: 1.4540246725082397\n",
            "Step 3000, Loss: 0.6389461159706116\n",
            "Step 3000, Generated Text: Once upon a time may not, myself are but negligence ill- Grey.\n",
            "If oft'd; n ethic and']):']):']):']):']): night night by my poor deeds. 'tis from guide.\n",
            "There shall at your own own with death.\n",
            "Step 3010, Loss: 0.6669530272483826\n",
            "Step 3020, Loss: 0.868266224861145\n",
            "Step 3030, Loss: 0.6579203009605408\n",
            "Step 3040, Loss: 0.5493890643119812\n",
            "Step 3050, Loss: 0.49756795167922974\n",
            "Step 3060, Loss: 0.9715111255645752\n",
            "Step 3070, Loss: 0.7684302926063538\n",
            "Step 3080, Loss: 0.5854913592338562\n",
            "Step 3090, Loss: 0.5407008528709412\n",
            "Step 3100, Loss: 0.9162091016769409\n",
            "Step 3110, Loss: 0.5651402473449707\n",
            "Step 3120, Loss: 0.6386394500732422\n",
            "Step 3130, Loss: 0.5381897687911987\n",
            "Step 3140, Loss: 0.7533649206161499\n",
            "Step 3150, Loss: 0.6558037996292114\n",
            "Step 3160, Loss: 0.7347123622894287\n",
            "Step 3170, Loss: 0.708853542804718\n",
            "Step 3180, Loss: 0.6540802717208862\n",
            "Step 3190, Loss: 0.8912018537521362\n",
            "Step 3200, Loss: 0.7193765640258789\n",
            "Step 3210, Loss: 0.6413383483886719\n",
            "Step 3220, Loss: 0.8156927824020386\n",
            "Step 3230, Loss: 0.6783366799354553\n",
            "Step 3240, Loss: 0.714803159236908\n",
            "Step 3250, Loss: 0.833847165107727\n",
            "Step 3260, Loss: 0.8719313144683838\n",
            "Step 3270, Loss: 0.8296938538551331\n",
            "Step 3280, Loss: 1.3099274635314941\n",
            "Step 3290, Loss: 0.9533513784408569\n",
            "Step 3300, Loss: 0.7467664480209351\n",
            "Step 3310, Loss: 0.5449497699737549\n",
            "Step 3320, Loss: 1.0281176567077637\n",
            "Step 3330, Loss: 0.369060754776001\n",
            "Step 3340, Loss: 0.2988382577896118\n",
            "Step 3350, Loss: 0.2764289379119873\n",
            "Step 3360, Loss: 0.45313650369644165\n",
            "Step 3370, Loss: 0.4251357614994049\n",
            "Step 3380, Loss: 0.4177440106868744\n",
            "Step 3390, Loss: 0.31701892614364624\n",
            "Step 3400, Loss: 0.2671196758747101\n",
            "Step 3410, Loss: 0.32786238193511963\n",
            "Step 3420, Loss: 0.3833434581756592\n",
            "Step 3430, Loss: 0.23499566316604614\n",
            "Step 3440, Loss: 0.36147433519363403\n",
            "Step 3450, Loss: 0.42002323269844055\n",
            "Step 3460, Loss: 0.46276119351387024\n",
            "Step 3470, Loss: 0.6981784105300903\n",
            "Step 3480, Loss: 0.37581825256347656\n",
            "Step 3490, Loss: 0.5169915556907654\n",
            "Step 3500, Loss: 0.3974093794822693\n",
            "Step 3500, Generated Text: Once upon a time,\n",
            " is not away! O, this blessed blessed., a a bones, Plantagenet, madam,, at hand had no man with him, helpUnless, he President them of great both which creature, holy\n",
            "Step 3510, Loss: 0.49273163080215454\n",
            "Step 3520, Loss: 0.5416631698608398\n",
            "Step 3530, Loss: 0.38331007957458496\n",
            "Step 3540, Loss: 0.45111405849456787\n",
            "Step 3550, Loss: 0.4647713005542755\n",
            "Step 3560, Loss: 0.3389946222305298\n",
            "Step 3570, Loss: 0.29057249426841736\n",
            "Step 3580, Loss: 0.4088003635406494\n",
            "Step 3590, Loss: 0.38834211230278015\n",
            "Step 3600, Loss: 0.39650824666023254\n",
            "Step 3610, Loss: 0.48117610812187195\n",
            "Step 3620, Loss: 0.3128128945827484\n",
            "Step 3630, Loss: 0.526313066482544\n",
            "Step 3640, Loss: 0.6694471836090088\n",
            "Step 3650, Loss: 0.44430041313171387\n",
            "Step 3660, Loss: 0.5180306434631348\n",
            "Step 3670, Loss: 0.2132442593574524\n",
            "Step 3680, Loss: 0.36886849999427795\n",
            "Step 3690, Loss: 0.19932334125041962\n",
            "Step 3700, Loss: 0.3009161055088043\n",
            "Step 3710, Loss: 0.24363194406032562\n",
            "Step 3720, Loss: 0.2173604965209961\n",
            "Step 3730, Loss: 0.3470227122306824\n",
            "Step 3740, Loss: 0.19692467153072357\n",
            "Step 3750, Loss: 0.21617789566516876\n",
            "Step 3760, Loss: 0.21543091535568237\n",
            "Step 3770, Loss: 0.2897270619869232\n",
            "Step 3780, Loss: 0.32674506306648254\n",
            "Step 3790, Loss: 0.24675852060317993\n",
            "Step 3800, Loss: 0.2476966828107834\n",
            "Step 3810, Loss: 0.21003863215446472\n",
            "Step 3820, Loss: 0.26519128680229187\n",
            "Step 3830, Loss: 0.2780854403972626\n",
            "Step 3840, Loss: 0.33486106991767883\n",
            "Step 3850, Loss: 0.3133001923561096\n",
            "Step 3860, Loss: 0.23480859398841858\n",
            "Step 3870, Loss: 0.29347649216651917\n",
            "Step 3880, Loss: 0.3063153028488159\n",
            "Step 3890, Loss: 0.20400406420230865\n",
            "Step 3900, Loss: 0.35150453448295593\n",
            "Step 3910, Loss: 0.3374681770801544\n",
            "Step 3920, Loss: 0.31810835003852844\n",
            "Step 3930, Loss: 0.28682664036750793\n",
            "Step 3940, Loss: 0.3784917891025543\n",
            "Step 3950, Loss: 0.27232250571250916\n",
            "Step 3960, Loss: 0.3643704950809479\n",
            "Step 3970, Loss: 0.3656584322452545\n",
            "Step 3980, Loss: 0.28752797842025757\n",
            "Step 3990, Loss: 0.346749484539032\n",
            "Step 4000, Loss: 0.09164003282785416\n",
            "Step 4000, Generated Text: Once upon a time may\n",
            "ESCALUS:\n",
            " ammaterials wonder?\n",
            " early together:\n",
            "But is office office till thou have been\n",
            "Before his his.\n",
            "As:\n",
            "MENENIUS:\n",
            "MENENENIUS\n",
            "Step 4010, Loss: 0.17346125841140747\n",
            "Step 4020, Loss: 0.10671849548816681\n",
            "Step 4030, Loss: 0.17244450747966766\n",
            "Step 4040, Loss: 0.1919429451227188\n",
            "Step 4050, Loss: 0.16678474843502045\n",
            "Step 4060, Loss: 0.12587440013885498\n",
            "Step 4070, Loss: 0.23339708149433136\n",
            "Step 4080, Loss: 0.25008848309516907\n",
            "Step 4090, Loss: 0.1401446908712387\n",
            "Step 4100, Loss: 0.2034887820482254\n",
            "Step 4110, Loss: 0.21116016805171967\n",
            "Step 4120, Loss: 0.20621143281459808\n",
            "Step 4130, Loss: 0.24053820967674255\n",
            "Step 4140, Loss: 0.17499181628227234\n",
            "Step 4150, Loss: 0.20261269807815552\n",
            "Step 4160, Loss: 0.20231647789478302\n",
            "Step 4170, Loss: 0.23832103610038757\n",
            "Step 4180, Loss: 0.2733868956565857\n",
            "Step 4190, Loss: 0.1802239865064621\n",
            "Step 4200, Loss: 0.2428913414478302\n",
            "Step 4210, Loss: 0.24824102222919464\n",
            "Step 4220, Loss: 0.25275349617004395\n",
            "Step 4230, Loss: 0.22410449385643005\n",
            "Step 4240, Loss: 0.24208132922649384\n",
            "Step 4250, Loss: 0.23880153894424438\n",
            "Step 4260, Loss: 0.13933947682380676\n",
            "Step 4270, Loss: 0.2513209283351898\n",
            "Step 4280, Loss: 0.2400795817375183\n",
            "Step 4290, Loss: 0.2673757076263428\n",
            "Step 4300, Loss: 0.22049348056316376\n",
            "Step 4310, Loss: 0.2380213588476181\n",
            "Step 4320, Loss: 0.2197868674993515\n",
            "Step 4330, Loss: 0.11948708444833755\n",
            "Step 4340, Loss: 0.07554826885461807\n",
            "Step 4350, Loss: 0.19016128778457642\n",
            "Step 4360, Loss: 0.1227344498038292\n",
            "Step 4370, Loss: 0.13357104361057281\n",
            "Step 4380, Loss: 0.11697888374328613\n",
            "Step 4390, Loss: 0.10001350194215775\n",
            "Step 4400, Loss: 0.11945071071386337\n",
            "Step 4410, Loss: 0.1569395810365677\n",
            "Step 4420, Loss: 0.1442173272371292\n",
            "Step 4430, Loss: 0.18377909064292908\n",
            "Step 4440, Loss: 0.16105875372886658\n",
            "Step 4450, Loss: 0.2169569432735443\n",
            "Step 4460, Loss: 0.1824737787246704\n",
            "Step 4470, Loss: 0.200905904173851\n",
            "Step 4480, Loss: 0.1774289309978485\n",
            "Step 4490, Loss: 0.18611054122447968\n",
            "Step 4500, Loss: 0.18707121908664703\n",
            "Step 4500, Generated Text: Once upon a time,\n",
            " pMy way,\n",
            "the deck my fasc RatherChe, I'll notIRANUS:\n",
            "GGLOUCIO:\n",
            "GAR:\n",
            "Yet hold.\n",
            "EXET:\n",
            "First Senator:\n",
            "Come\n",
            "Step 4510, Loss: 0.2411063313484192\n",
            "Step 4520, Loss: 0.16240718960762024\n",
            "Step 4530, Loss: 0.25885269045829773\n",
            "Step 4540, Loss: 0.18321533501148224\n",
            "Step 4550, Loss: 0.13541273772716522\n",
            "Step 4560, Loss: 0.23156127333641052\n",
            "Step 4570, Loss: 0.19652605056762695\n",
            "Step 4580, Loss: 0.24122877418994904\n",
            "Step 4590, Loss: 0.22297511994838715\n",
            "Step 4600, Loss: 0.24452152848243713\n",
            "Step 4610, Loss: 0.23888830840587616\n",
            "Step 4620, Loss: 0.1787298619747162\n",
            "Step 4630, Loss: 0.2413313239812851\n",
            "Step 4640, Loss: 0.22271870076656342\n",
            "Step 4650, Loss: 0.20539043843746185\n",
            "Step 4660, Loss: 0.22476303577423096\n",
            "Step 4670, Loss: 0.07399307191371918\n",
            "Step 4680, Loss: 0.07698547840118408\n",
            "Step 4690, Loss: 0.1325445920228958\n",
            "Step 4700, Loss: 0.177316814661026\n",
            "Step 4710, Loss: 0.11696342378854752\n",
            "Step 4720, Loss: 0.09315244853496552\n",
            "Step 4730, Loss: 0.14138831198215485\n",
            "Step 4740, Loss: 0.1586107760667801\n",
            "Step 4750, Loss: 0.1441483050584793\n",
            "Step 4760, Loss: 0.08940475434064865\n",
            "Step 4770, Loss: 0.17990271747112274\n",
            "Step 4780, Loss: 0.12239176034927368\n",
            "Step 4790, Loss: 0.16678118705749512\n",
            "Step 4800, Loss: 0.23087555170059204\n",
            "Step 4810, Loss: 0.1863107532262802\n",
            "Step 4820, Loss: 0.10246371477842331\n",
            "Step 4830, Loss: 0.20076008141040802\n",
            "Step 4840, Loss: 0.16730497777462006\n",
            "Step 4850, Loss: 0.1273496150970459\n",
            "Step 4860, Loss: 0.16105756163597107\n",
            "Step 4870, Loss: 0.26580098271369934\n",
            "Step 4880, Loss: 0.21244698762893677\n",
            "Step 4890, Loss: 0.1755293607711792\n",
            "Step 4900, Loss: 0.24087779223918915\n",
            "Step 4910, Loss: 0.18428334593772888\n",
            "Step 4920, Loss: 0.18250232934951782\n",
            "Step 4930, Loss: 0.17783722281455994\n",
            "Step 4940, Loss: 0.1567383110523224\n",
            "Step 4950, Loss: 0.1757049411535263\n",
            "Step 4960, Loss: 0.19203722476959229\n",
            "Step 4970, Loss: 0.15291473269462585\n",
            "Step 4980, Loss: 0.16993753612041473\n",
            "Step 4990, Loss: 0.18106824159622192\n",
            "Checkpoint saved at checkpoints/checkpoint_5000.pt\n",
            "Starting Phase 2: Loading checkpoint and training for 50 more steps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-26cbe3f04d50>:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded checkpoint from checkpoints/checkpoint_5000.pt at step 5000\n",
            "Step 5000, Loss: 0.07633372396230698\n",
            "Step 5000, Generated Text: Once upon a time,\n",
            " loved theeylon, my their superintendent?\n",
            "As kept aly and a provided, and have leave, for the concerns,\n",
            "A Boundaries, a sw swungung justlyed by the state state state state state\n",
            "Step 5010, Loss: 0.06234195455908775\n",
            "Step 5020, Loss: 0.1018715649843216\n",
            "Step 5030, Loss: 0.06651565432548523\n",
            "Step 5040, Loss: 0.17842015624046326\n",
            "Checkpoint saved at checkpoints/checkpoint_5050.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n"
      ],
      "metadata": {
        "id": "iRUNWdIj5lyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('/content/checkpoints/checkpoint_5000.pt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "4mCVEqsGdbjx",
        "outputId": "5ec82162-8a61-407a-8095-120c8eaf8d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_656ff9ed-134b-41f7-9b92-be80bda984b0\", \"checkpoint_5000.pt\", 1630793278)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('/content/checkpoints/checkpoint_5050.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "9froLzBsdgNa",
        "outputId": "ac498267-3592-4045-9e46-50f25f264d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_14dce26e-4b1d-4d1e-91c3-6337f5eb1ba6\", \"checkpoint_5050.pt\", 1630793278)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r checkpoint_files.zip /content/checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBrcOynNeI2m",
        "outputId": "e4e5592b-7de6-4de5-985c-fdd8c548e42f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/checkpoints/ (stored 0%)\n",
            "  adding: content/checkpoints/checkpoint_5050.pt (deflated 10%)\n",
            "  adding: content/checkpoints/checkpoint_5000.pt (deflated 10%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('checkpoint_files.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "bbD9uQqxfTDM",
        "outputId": "385df40c-4bf5-4eb7-d1d4-f728bd1af4d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3a5856e3-7fda-4d82-a553-0f9325ef679e\", \"checkpoint_files.zip\", 2941604480)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64x748Zmffl-",
        "outputId": "6e0e8b1e-f2ab-4efb-98bd-bcfc56667b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/checkpoint_files.zip /content/drive/MyDrive/\n"
      ],
      "metadata": {
        "id": "6d5swRwQfgXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Data from drive for quantization"
      ],
      "metadata": {
        "id": "QBpTBpqGp6Sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TcrBDVlffyjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aae292a-d29e-456f-d255-a576ddb53e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the zip file in Google Drive\n",
        "zip_path = \"/content/drive/MyDrive/checkpoint_files.zip\"\n",
        "\n",
        "# Directory to extract the contents\n",
        "extract_dir = \"/content/checkpoint\"\n",
        "\n",
        "# Create the extraction directory\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(\"Extraction complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q85ybGxup5JU",
        "outputId": "796583b1-7ff6-4811-ac48-1bcdc2e74947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now load the model from extracted checkpoint"
      ],
      "metadata": {
        "id": "Ku8_H7aEqxMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# from model import TransformerModel  # Replace with your model class\n",
        "\n",
        "# Path to the checkpoint file\n",
        "checkpoint_path = os.path.join(\"/content/checkpoint/content/checkpoints\", \"checkpoint_5050.pt\")\n",
        "\n",
        "# Load the model architecture\n",
        "# model = TransformerModel(...)  # Initialize with the same architecture\n",
        "\n",
        "# Load the checkpoint\n",
        "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "model.eval()  # Set the model to evaluation mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz2KVWphqYH0",
        "outputId": "978fe106-a15b-4a22-ffc6-84862b9a14fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-cd0b8cdec315>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerModel(\n",
              "  (embed_tokens): Embedding(49152, 576)\n",
              "  (embed_positions): Embedding(2048, 576)\n",
              "  (layers): ModuleList(\n",
              "    (0-29): 30 x TransformerBlock(\n",
              "      (q_proj): Linear(in_features=576, out_features=576, bias=True)\n",
              "      (k_proj): Linear(in_features=576, out_features=192, bias=True)\n",
              "      (v_proj): Linear(in_features=576, out_features=192, bias=True)\n",
              "      (o_proj): Linear(in_features=576, out_features=576, bias=True)\n",
              "      (gate_proj): Linear(in_features=576, out_features=1536, bias=True)\n",
              "      (up_proj): Linear(in_features=576, out_features=1536, bias=True)\n",
              "      (down_proj): Linear(in_features=1536, out_features=576, bias=True)\n",
              "      (input_norm): RMSNorm()\n",
              "      (post_attention_norm): RMSNorm()\n",
              "      (act): SiLU()\n",
              "      (rope): RotaryPositionalEmbedding()\n",
              "    )\n",
              "  )\n",
              "  (final_norm): RMSNorm()\n",
              "  (lm_head): Linear(in_features=576, out_features=49152, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New"
      ],
      "metadata": {
        "id": "F8yH3nVWQvwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.quantization\n",
        "\n",
        "# Specify which layers to quantize. \"nn.Linear\" is common.\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    model,\n",
        "    {nn.Linear},  # This can be a set of layer types to quantize\n",
        "    dtype=torch.qint8  # 8-bit integer quantization\n",
        ")\n",
        "\n",
        "# Now `quantized_model` is quantized\n",
        "torch.save(quantized_model, \"quantized_model.pt\")\n",
        "print(\"Quantized model saved to 'quantized_model.pt'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZBCjbt6Qsyi",
        "outputId": "dcdc67d9-5238-474c-c3b0-911ba40b4be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized model saved to 'quantized_model.pt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Move quantized model to google drive"
      ],
      "metadata": {
        "id": "T48qc_zZRnCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define the source and destination paths\n",
        "source_path = \"/content/quantized_model.pt\"\n",
        "destination_path = \"/content/drive/MyDrive/quantized_model.pt\"  # Save it to the root of your Google Drive\n",
        "\n",
        "# Copy the file\n",
        "shutil.copy(source_path, destination_path)\n",
        "\n",
        "print(f\"Model checkpoint copied to Google Drive: {destination_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYG7HSE2RmdV",
        "outputId": "b5b69aed-2742-47bb-cc7a-eaab3b66255e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model checkpoint copied to Google Drive: /content/drive/MyDrive/quantized_model.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OLD"
      ],
      "metadata": {
        "id": "EI4Zr0WJQt6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantize the model to float16\n",
        "model.half()  # Convert model weights to float16\n",
        "\n",
        "# Save the quantized model\n",
        "quantized_checkpoint_path = os.path.join(\"/content/checkpoint/content/checkpoints\", \"checkpoint_quantized.pt\")\n",
        "torch.save(model.state_dict(), quantized_checkpoint_path)\n",
        "\n",
        "print(\"Quantization complete! Quantized model saved at:\", quantized_checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RggZVpfCq-w6",
        "outputId": "f75c9a32-86dc-427b-c4bf-39a0802d9d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantization complete! Quantized model saved at: /content/checkpoint/content/checkpoints/checkpoint_quantized.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Move quantized model from googlecolan to googledrive"
      ],
      "metadata": {
        "id": "sgdjHbXStgrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define the source and destination paths\n",
        "source_path = \"/content/checkpoint/content/checkpoints/checkpoint_quantized.pt\"\n",
        "destination_path = \"/content/drive/MyDrive/checkpoint_quantized.pt\"  # Save it to the root of your Google Drive\n",
        "\n",
        "# Copy the file\n",
        "shutil.copy(source_path, destination_path)\n",
        "\n",
        "print(f\"Model checkpoint copied to Google Drive: {destination_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nf7luNlrndN",
        "outputId": "3e3057af-c74e-401a-9424-0060f0d965c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model checkpoint copied to Google Drive: /content/drive/MyDrive/checkpoint_quantized.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0sh7y0RsjrF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "T2DL8Xtfjqvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Updated code"
      ],
      "metadata": {
        "id": "vnkgh_41jqj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer\n",
        "import json\n",
        "import os\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# You must ensure that create_model_from_config is imported from your model.py\n",
        "# or defined here. For example:\n",
        "#\n",
        "# from model import create_model_from_config\n",
        "#\n",
        "# If you prefer to define it inline, uncomment below (and ensure model.py is not conflicting):\n",
        "#\n",
        "# from model import TransformerModel\n",
        "# def create_model_from_config(config):\n",
        "#     model_config = config[\"model\"][\"model_config\"]\n",
        "#     return TransformerModel(\n",
        "#         vocab_size=model_config[\"vocab_size\"],\n",
        "#         hidden_size=model_config[\"hidden_size\"],\n",
        "#         num_hidden_layers=model_config[\"num_hidden_layers\"],\n",
        "#         num_attention_heads=model_config[\"num_attention_heads\"],\n",
        "#         intermediate_size=model_config[\"intermediate_size\"],\n",
        "#         num_key_value_heads=model_config[\"num_key_value_heads\"],\n",
        "#         max_position_embeddings=model_config[\"max_position_embeddings\"],\n",
        "#         rms_norm_eps=model_config[\"rms_norm_eps\"],\n",
        "#         hidden_act=model_config[\"hidden_act\"],\n",
        "#         tie_word_embeddings=model_config[\"tie_word_embeddings\"],\n",
        "#     )\n",
        "#\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# Configuration\n",
        "CONFIG_FILE = \"config_smollm2_135M.json\"\n",
        "CHECKPOINT_DIR = \"checkpoints\"\n",
        "BATCH_SIZE = 2         # Reduced batch size\n",
        "SEQ_LENGTH = 512       # Reduced sequence length\n",
        "GRADIENT_ACCUMULATION_STEPS = 1\n",
        "PREDICTION_INTERVAL = 500\n",
        "TRAIN_STEPS_PHASE_1 = 5000\n",
        "TRAIN_STEPS_PHASE_2 = 50\n",
        "\n",
        "# Load the configuration\n",
        "with open(CONFIG_FILE, \"r\") as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "# Set up the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(config[\"tokenizer\"][\"tokenizer_name_or_path\"])\n",
        "print(\"Tokenizer vocab size:\", tokenizer.vocab_size)\n",
        "print(\"Model vocab size:\", config[\"model\"][\"model_config\"][\"vocab_size\"])\n",
        "\n",
        "# Ensure tokenizer vocab size matches model vocab size\n",
        "assert tokenizer.vocab_size == config[\"model\"][\"model_config\"][\"vocab_size\"], \\\n",
        "    \"Tokenizer vocab size does not match model vocab size\"\n",
        "\n",
        "# Add pad_token_id to model config if missing\n",
        "if \"pad_token_id\" not in config[\"model\"][\"model_config\"]:\n",
        "    config[\"model\"][\"model_config\"][\"pad_token_id\"] = tokenizer.pad_token_id\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# Create/Load your model from config\n",
        "# (Uncomment or replace with your own import)\n",
        "# --------------------------------------------------------------------------\n",
        "# from model import create_model_from_config\n",
        "model = create_model_from_config(config).to(device)\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# Define the optimizer with a lower learning rate\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=1e-4,  # Reduced learning rate\n",
        "    betas=(\n",
        "        config[\"optimizer\"][\"optimizer_factory\"][\"adam_beta1\"],\n",
        "        config[\"optimizer\"][\"optimizer_factory\"][\"adam_beta2\"],\n",
        "    ),\n",
        "    eps=config[\"optimizer\"][\"optimizer_factory\"][\"adam_eps\"],\n",
        "    weight_decay=config[\"optimizer\"][\"weight_decay\"],\n",
        ")\n",
        "\n",
        "# Define the loss function\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialize GradScaler for mixed precision\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Simple text dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, file_path, tokenizer, seq_length):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.seq_length = seq_length\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            self.text = f.read()\n",
        "        self.tokens = self.tokenizer.encode(self.text)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens) // self.seq_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start = idx * self.seq_length\n",
        "        end = start + self.seq_length\n",
        "        input_ids = self.tokens[start:end]\n",
        "        labels = self.tokens[start + 1 : end + 1]\n",
        "        return torch.tensor(input_ids, dtype=torch.long), torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "# Load the dataset\n",
        "dataset = TextDataset(\"input.txt\", tokenizer, SEQ_LENGTH)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Function to generate text for logging/preview\n",
        "def generate_text(model, tokenizer, prompt=\"\", max_length=50):\n",
        "    \"\"\"\n",
        "    Generate text using the model.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    # Encode the prompt\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Generate text\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(input_ids, max_length=max_length, do_sample=True)\n",
        "\n",
        "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# Training loop\n",
        "def train(initial_step=0, total_steps=5000, checkpoint_path=None):\n",
        "    model.train()\n",
        "    global_step = initial_step\n",
        "\n",
        "    # Load checkpoint if provided\n",
        "    if checkpoint_path:\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "        global_step = checkpoint[\"global_step\"]\n",
        "        print(f\"Loaded checkpoint from {checkpoint_path} at step {global_step}\")\n",
        "\n",
        "    while global_step < total_steps:\n",
        "        for batch_idx, (input_ids, labels) in enumerate(dataloader):\n",
        "            input_ids = input_ids.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass with mixed precision\n",
        "            with autocast():\n",
        "                outputs = model(input_ids)\n",
        "                loss = loss_fn(outputs.view(-1, outputs.size(-1)), labels.view(-1))\n",
        "\n",
        "            # Check for NaN or inf\n",
        "            if torch.isnan(loss).any() or torch.isinf(loss).any():\n",
        "                print(\"Loss is nan or inf. Stopping training.\")\n",
        "                return\n",
        "\n",
        "            # Backward pass with gradient scaling\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            # Gradient accumulation\n",
        "            if (batch_idx + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            # Logging\n",
        "            if global_step % 10 == 0:\n",
        "                print(f\"Step {global_step}, Loss: {loss.item()}\")\n",
        "\n",
        "            # Generate text every PREDICTION_INTERVAL steps\n",
        "            if global_step % PREDICTION_INTERVAL == 0:\n",
        "                gen_txt = generate_text(model, tokenizer, prompt=\"Once upon a time\")\n",
        "                print(f\"Step {global_step}, Generated Text: {gen_txt}\")\n",
        "\n",
        "            global_step += 1\n",
        "            if global_step >= total_steps:\n",
        "                break\n",
        "\n",
        "    # Save a full checkpoint (includes optimizer) for possible further training\n",
        "    checkpoint_path = os.path.join(CHECKPOINT_DIR, f\"checkpoint_{global_step}.pt\")\n",
        "    torch.save(\n",
        "        {\n",
        "            \"global_step\": global_step,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"loss\": loss.item(),\n",
        "        },\n",
        "        checkpoint_path,\n",
        "    )\n",
        "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
        "\n",
        "# Create the checkpoint directory if it doesn't exist\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "# Phase 1: Train for 5000 steps\n",
        "print(\"Starting Phase 1: Training for 5000 steps\")\n",
        "train(initial_step=0, total_steps=TRAIN_STEPS_PHASE_1)\n",
        "\n",
        "# Phase 2: Load the checkpoint from Phase 1 and train 50 more steps\n",
        "print(\"Starting Phase 2: Loading checkpoint and training for 50 more steps\")\n",
        "phase1_ckpt = os.path.join(CHECKPOINT_DIR, f\"checkpoint_{TRAIN_STEPS_PHASE_1}.pt\")\n",
        "train(\n",
        "    initial_step=TRAIN_STEPS_PHASE_1,\n",
        "    total_steps=TRAIN_STEPS_PHASE_1 + TRAIN_STEPS_PHASE_2,\n",
        "    checkpoint_path=phase1_ckpt\n",
        ")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# FINAL STEP: Create a smaller inference checkpoint in FP16, omitting optimizer\n",
        "# ------------------------------------------------------------------------------\n",
        "final_ckpt_path = os.path.join(CHECKPOINT_DIR, f\"checkpoint_{TRAIN_STEPS_PHASE_1 + TRAIN_STEPS_PHASE_2}.pt\")\n",
        "print(f\"\\nLoading final training checkpoint: {final_ckpt_path}\")\n",
        "checkpoint = torch.load(final_ckpt_path, map_location=\"cpu\")\n",
        "\n",
        "fp32_state_dict = checkpoint[\"model_state_dict\"]\n",
        "\n",
        "# Convert all float32 params to float16\n",
        "half_state_dict = {}\n",
        "for name, param in fp32_state_dict.items():\n",
        "    if param.dtype == torch.float32:\n",
        "        half_state_dict[name] = param.half()\n",
        "    else:\n",
        "        half_state_dict[name] = param  # keep other dtypes as is\n",
        "\n",
        "# Build the smaller checkpoint for inference\n",
        "inference_checkpoint = {\n",
        "    \"global_step\": checkpoint[\"global_step\"],\n",
        "    \"model_state_dict\": half_state_dict\n",
        "    # optimizer_state_dict is omitted\n",
        "}\n",
        "\n",
        "inference_ckpt_path = os.path.join(CHECKPOINT_DIR, \"model_weights_fp16.pt\")\n",
        "torch.save(inference_checkpoint, inference_ckpt_path)\n",
        "print(f\"Inference checkpoint (FP16) saved at {inference_ckpt_path}\")\n",
        "\n",
        "print(\"Done! You can upload 'model_weights_fp16.pt' (well under 1 GB) to Spaces.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFVPvqZTjry-",
        "outputId": "b47bdbf8-5988-4634-9962-851e8aae427a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer vocab size: 49152\n",
            "Model vocab size: 49152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-de75ea64c958>:89: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Phase 1: Training for 5000 steps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-de75ea64c958>:148: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0, Loss: 297.957763671875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0, Generated Text: Once upon a time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time time\n",
            "Step 10, Loss: 157.36114501953125\n",
            "Step 20, Loss: 58.85614776611328\n",
            "Step 30, Loss: 46.871978759765625\n",
            "Step 40, Loss: 39.91062927246094\n",
            "Step 50, Loss: 39.27462387084961\n",
            "Step 60, Loss: 35.252784729003906\n",
            "Step 70, Loss: 34.14326858520508\n",
            "Step 80, Loss: 33.6908073425293\n",
            "Step 90, Loss: 30.927204132080078\n",
            "Step 100, Loss: 29.71237564086914\n",
            "Step 110, Loss: 30.40058135986328\n",
            "Step 120, Loss: 29.440732955932617\n",
            "Step 130, Loss: 29.94432258605957\n",
            "Step 140, Loss: 27.920412063598633\n",
            "Step 150, Loss: 27.681842803955078\n",
            "Step 160, Loss: 27.285734176635742\n",
            "Step 170, Loss: 25.474994659423828\n",
            "Step 180, Loss: 25.483720779418945\n",
            "Step 190, Loss: 28.43486785888672\n",
            "Step 200, Loss: 24.9284725189209\n",
            "Step 210, Loss: 26.502050399780273\n",
            "Step 220, Loss: 23.323963165283203\n",
            "Step 230, Loss: 22.96782112121582\n",
            "Step 240, Loss: 23.82254409790039\n",
            "Step 250, Loss: 20.913156509399414\n",
            "Step 260, Loss: 24.756206512451172\n",
            "Step 270, Loss: 22.64474105834961\n",
            "Step 280, Loss: 22.406864166259766\n",
            "Step 290, Loss: 24.060134887695312\n",
            "Step 300, Loss: 20.72429656982422\n",
            "Step 310, Loss: 20.762344360351562\n",
            "Step 320, Loss: 22.064926147460938\n",
            "Step 330, Loss: 18.61631202697754\n",
            "Step 340, Loss: 17.973466873168945\n",
            "Step 350, Loss: 21.548236846923828\n",
            "Step 360, Loss: 21.15456771850586\n",
            "Step 370, Loss: 19.971765518188477\n",
            "Step 380, Loss: 21.162609100341797\n",
            "Step 390, Loss: 17.794652938842773\n",
            "Step 400, Loss: 20.034523010253906\n",
            "Step 410, Loss: 19.624120712280273\n",
            "Step 420, Loss: 18.03474998474121\n",
            "Step 430, Loss: 16.3006591796875\n",
            "Step 440, Loss: 16.961360931396484\n",
            "Step 450, Loss: 16.6553955078125\n",
            "Step 460, Loss: 15.890033721923828\n",
            "Step 470, Loss: 17.053781509399414\n",
            "Step 480, Loss: 13.104148864746094\n",
            "Step 490, Loss: 16.881135940551758\n",
            "Step 500, Loss: 16.080419540405273\n",
            "Step 500, Generated Text: Once upon a time to theforestryforestryforestryforestryforestryforestryforestryforestryforestryforestryforestryforestryforestryforestryforestryforestryforestryforestryforestryforestry to be.\n",
            "ADDR down to the part part part part part part part part part part part part part part part of\n",
            "Step 510, Loss: 16.42127227783203\n",
            "Step 520, Loss: 14.520464897155762\n",
            "Step 530, Loss: 14.912958145141602\n",
            "Step 540, Loss: 15.325052261352539\n",
            "Step 550, Loss: 16.350229263305664\n",
            "Step 560, Loss: 16.018081665039062\n",
            "Step 570, Loss: 14.70682430267334\n",
            "Step 580, Loss: 15.643199920654297\n",
            "Step 590, Loss: 15.360724449157715\n",
            "Step 600, Loss: 13.392953872680664\n",
            "Step 610, Loss: 13.912443161010742\n",
            "Step 620, Loss: 13.709465980529785\n",
            "Step 630, Loss: 11.719894409179688\n",
            "Step 640, Loss: 13.739377975463867\n",
            "Step 650, Loss: 12.705365180969238\n",
            "Step 660, Loss: 11.45716667175293\n",
            "Step 670, Loss: 11.971237182617188\n",
            "Step 680, Loss: 12.323800086975098\n",
            "Step 690, Loss: 14.213766098022461\n",
            "Step 700, Loss: 13.893470764160156\n",
            "Step 710, Loss: 11.848470687866211\n",
            "Step 720, Loss: 11.013607025146484\n",
            "Step 730, Loss: 9.562789916992188\n",
            "Step 740, Loss: 10.830889701843262\n",
            "Step 750, Loss: 11.448382377624512\n",
            "Step 760, Loss: 10.623636245727539\n",
            "Step 770, Loss: 13.306936264038086\n",
            "Step 780, Loss: 12.871480941772461\n",
            "Step 790, Loss: 10.530226707458496\n",
            "Step 800, Loss: 11.2627534866333\n",
            "Step 810, Loss: 10.853743553161621\n",
            "Step 820, Loss: 10.996868133544922\n",
            "Step 830, Loss: 10.055331230163574\n",
            "Step 840, Loss: 10.119874954223633\n",
            "Step 850, Loss: 11.26650333404541\n",
            "Step 860, Loss: 10.710700035095215\n",
            "Step 870, Loss: 11.505804061889648\n",
            "Step 880, Loss: 10.242452621459961\n",
            "Step 890, Loss: 8.821720123291016\n",
            "Step 900, Loss: 11.255119323730469\n",
            "Step 910, Loss: 8.952176094055176\n",
            "Step 920, Loss: 9.658339500427246\n",
            "Step 930, Loss: 10.314126968383789\n",
            "Step 940, Loss: 11.406210899353027\n",
            "Step 950, Loss: 9.807185173034668\n",
            "Step 960, Loss: 9.561838150024414\n",
            "Step 970, Loss: 11.96743106842041\n",
            "Step 980, Loss: 10.849571228027344\n",
            "Step 990, Loss: 10.174650192260742\n",
            "Step 1000, Loss: 7.041624546051025\n",
            "Step 1000, Generated Text: Once upon a time, and by\n",
            "DUCHESS, thou again; for thisHath I can\n",
            "\n",
            "And you, or say the murder; you all?\n",
            "And I'er.\n",
            "To be the cross\n",
            "\n",
            "QUEEN\n",
            "Step 1010, Loss: 8.776960372924805\n",
            "Step 1020, Loss: 8.848257064819336\n",
            "Step 1030, Loss: 7.6367316246032715\n",
            "Step 1040, Loss: 9.271312713623047\n",
            "Step 1050, Loss: 11.035835266113281\n",
            "Step 1060, Loss: 9.710198402404785\n",
            "Step 1070, Loss: 9.852819442749023\n",
            "Step 1080, Loss: 7.572943210601807\n",
            "Step 1090, Loss: 8.136948585510254\n",
            "Step 1100, Loss: 9.125448226928711\n",
            "Step 1110, Loss: 7.927872657775879\n",
            "Step 1120, Loss: 8.66563606262207\n",
            "Step 1130, Loss: 8.636272430419922\n",
            "Step 1140, Loss: 7.851866245269775\n",
            "Step 1150, Loss: 8.587889671325684\n",
            "Step 1160, Loss: 8.26001262664795\n",
            "Step 1170, Loss: 8.723064422607422\n",
            "Step 1180, Loss: 8.229070663452148\n",
            "Step 1190, Loss: 8.024581909179688\n",
            "Step 1200, Loss: 7.849086284637451\n",
            "Step 1210, Loss: 7.2841010093688965\n",
            "Step 1220, Loss: 7.70722770690918\n",
            "Step 1230, Loss: 8.406383514404297\n",
            "Step 1240, Loss: 7.610863208770752\n",
            "Step 1250, Loss: 9.85431957244873\n",
            "Step 1260, Loss: 8.873897552490234\n",
            "Step 1270, Loss: 7.705086708068848\n",
            "Step 1280, Loss: 7.352869510650635\n",
            "Step 1290, Loss: 7.469425678253174\n",
            "Step 1300, Loss: 5.82699728012085\n",
            "Step 1310, Loss: 7.990833282470703\n",
            "Step 1320, Loss: 7.81771993637085\n",
            "Step 1330, Loss: 8.286752700805664\n",
            "Step 1340, Loss: 7.496439456939697\n",
            "Step 1350, Loss: 8.015028953552246\n",
            "Step 1360, Loss: 7.705839157104492\n",
            "Step 1370, Loss: 5.624629974365234\n",
            "Step 1380, Loss: 7.431723594665527\n",
            "Step 1390, Loss: 6.795220375061035\n",
            "Step 1400, Loss: 6.7000017166137695\n",
            "Step 1410, Loss: 6.450299263000488\n",
            "Step 1420, Loss: 5.833403587341309\n",
            "Step 1430, Loss: 6.500787258148193\n",
            "Step 1440, Loss: 6.040172100067139\n",
            "Step 1450, Loss: 6.9636549949646\n",
            "Step 1460, Loss: 7.132369518280029\n",
            "Step 1470, Loss: 6.248780727386475\n",
            "Step 1480, Loss: 5.865836143493652\n",
            "Step 1490, Loss: 6.076676368713379\n",
            "Step 1500, Loss: 5.292909622192383\n",
            "Step 1500, Generated Text: Once upon a time time.\n",
            "This highnessness of his father: and me now, and wept men.\n",
            "Hath now, and the lords,\n",
            "H thing you? and his pray you?\n",
            "But thus. Come, and\n",
            "Step 1510, Loss: 6.693940162658691\n",
            "Step 1520, Loss: 6.740947723388672\n",
            "Step 1530, Loss: 6.069265842437744\n",
            "Step 1540, Loss: 7.04843282699585\n",
            "Step 1550, Loss: 6.313290119171143\n",
            "Step 1560, Loss: 6.688805103302002\n",
            "Step 1570, Loss: 6.101678371429443\n",
            "Step 1580, Loss: 6.003524303436279\n",
            "Step 1590, Loss: 7.865908622741699\n",
            "Step 1600, Loss: 7.085030555725098\n",
            "Step 1610, Loss: 6.611052513122559\n",
            "Step 1620, Loss: 7.231212139129639\n",
            "Step 1630, Loss: 5.986349105834961\n",
            "Step 1640, Loss: 7.462873458862305\n",
            "Step 1650, Loss: 6.9031453132629395\n",
            "Step 1660, Loss: 6.574064254760742\n",
            "Step 1670, Loss: 5.236675262451172\n",
            "Step 1680, Loss: 5.077760219573975\n",
            "Step 1690, Loss: 4.718262195587158\n",
            "Step 1700, Loss: 7.262035369873047\n",
            "Step 1710, Loss: 6.111631393432617\n",
            "Step 1720, Loss: 6.698849201202393\n",
            "Step 1730, Loss: 5.617074489593506\n",
            "Step 1740, Loss: 7.033918380737305\n",
            "Step 1750, Loss: 6.5604119300842285\n",
            "Step 1760, Loss: 5.337925910949707\n",
            "Step 1770, Loss: 6.788270473480225\n",
            "Step 1780, Loss: 5.946129322052002\n",
            "Step 1790, Loss: 5.9828290939331055\n",
            "Step 1800, Loss: 5.199220657348633\n",
            "Step 1810, Loss: 5.302089214324951\n",
            "Step 1820, Loss: 6.066252708435059\n",
            "Step 1830, Loss: 5.405862331390381\n",
            "Step 1840, Loss: 6.575196266174316\n",
            "Step 1850, Loss: 4.817558765411377\n",
            "Step 1860, Loss: 6.089399814605713\n",
            "Step 1870, Loss: 5.0103936195373535\n",
            "Step 1880, Loss: 5.574275970458984\n",
            "Step 1890, Loss: 5.412161350250244\n",
            "Step 1900, Loss: 5.837680816650391\n",
            "Step 1910, Loss: 6.385309219360352\n",
            "Step 1920, Loss: 6.672000408172607\n",
            "Step 1930, Loss: 6.106015205383301\n",
            "Step 1940, Loss: 4.895359992980957\n",
            "Step 1950, Loss: 4.931332111358643\n",
            "Step 1960, Loss: 5.095085144042969\n",
            "Step 1970, Loss: 5.3579301834106445\n",
            "Step 1980, Loss: 5.320931434631348\n",
            "Step 1990, Loss: 5.090501308441162\n",
            "Step 2000, Loss: 4.762176513671875\n",
            "Step 2000, Generated Text: Once upon a time time to\n",
            "My sovereign sovereign's friend, my mind strange strange of 'sman:\n",
            "His old age,\n",
            "Who repeal repeal af af af af take it inkingking more:\n",
            "Thou:\n",
            "ComeCome,\n",
            "Step 2010, Loss: 4.3287835121154785\n",
            "Step 2020, Loss: 4.9318671226501465\n",
            "Step 2030, Loss: 3.6249773502349854\n",
            "Step 2040, Loss: 3.824545383453369\n",
            "Step 2050, Loss: 4.184811592102051\n",
            "Step 2060, Loss: 4.515706539154053\n",
            "Step 2070, Loss: 4.913785457611084\n",
            "Step 2080, Loss: 4.415811061859131\n",
            "Step 2090, Loss: 4.1738080978393555\n",
            "Step 2100, Loss: 4.246840000152588\n",
            "Step 2110, Loss: 4.005212783813477\n",
            "Step 2120, Loss: 3.8601720333099365\n",
            "Step 2130, Loss: 4.129505634307861\n",
            "Step 2140, Loss: 4.2097907066345215\n",
            "Step 2150, Loss: 2.568984031677246\n",
            "Step 2160, Loss: 4.948603630065918\n",
            "Step 2170, Loss: 4.430514335632324\n",
            "Step 2180, Loss: 5.1156768798828125\n",
            "Step 2190, Loss: 4.8341779708862305\n",
            "Step 2200, Loss: 4.254190921783447\n",
            "Step 2210, Loss: 4.434135913848877\n",
            "Step 2220, Loss: 3.9126639366149902\n",
            "Step 2230, Loss: 4.253726482391357\n",
            "Step 2240, Loss: 4.515440940856934\n",
            "Step 2250, Loss: 4.341965198516846\n",
            "Step 2260, Loss: 3.600444793701172\n",
            "Step 2270, Loss: 4.345357894897461\n",
            "Step 2280, Loss: 4.182461261749268\n",
            "Step 2290, Loss: 3.7477049827575684\n",
            "Step 2300, Loss: 4.5045881271362305\n",
            "Step 2310, Loss: 4.201037883758545\n",
            "Step 2320, Loss: 3.386198043823242\n",
            "Step 2330, Loss: 4.084120273590088\n",
            "Step 2340, Loss: 2.7295892238616943\n",
            "Step 2350, Loss: 2.660205364227295\n",
            "Step 2360, Loss: 2.392010450363159\n",
            "Step 2370, Loss: 3.161364793777466\n",
            "Step 2380, Loss: 2.8861887454986572\n",
            "Step 2390, Loss: 2.847095251083374\n",
            "Step 2400, Loss: 2.8372855186462402\n",
            "Step 2410, Loss: 2.6178343296051025\n",
            "Step 2420, Loss: 2.4738757610321045\n",
            "Step 2430, Loss: 3.6435229778289795\n",
            "Step 2440, Loss: 2.9013288021087646\n",
            "Step 2450, Loss: 2.854149580001831\n",
            "Step 2460, Loss: 2.2776589393615723\n",
            "Step 2470, Loss: 2.180295944213867\n",
            "Step 2480, Loss: 2.739107608795166\n",
            "Step 2490, Loss: 3.017703056335449\n",
            "Step 2500, Loss: 3.105381965637207\n",
            "Step 2500, Generated Text: Once upon a time time of\n",
            "And, in which the perceive perceive it\n",
            "WARWICK:\n",
            "Let's top top top top top top about about her in the many guests guests guests? What's death; at peace:\n",
            "And I one\n",
            "Step 2510, Loss: 2.1786787509918213\n",
            "Step 2520, Loss: 2.6688616275787354\n",
            "Step 2530, Loss: 2.992032289505005\n",
            "Step 2540, Loss: 2.7505264282226562\n",
            "Step 2550, Loss: 2.3640191555023193\n",
            "Step 2560, Loss: 2.2430965900421143\n",
            "Step 2570, Loss: 2.6280558109283447\n",
            "Step 2580, Loss: 2.7939834594726562\n",
            "Step 2590, Loss: 2.7313790321350098\n",
            "Step 2600, Loss: 2.423534870147705\n",
            "Step 2610, Loss: 2.834489583969116\n",
            "Step 2620, Loss: 2.740554094314575\n",
            "Step 2630, Loss: 2.873857259750366\n",
            "Step 2640, Loss: 2.345499277114868\n",
            "Step 2650, Loss: 2.723024606704712\n",
            "Step 2660, Loss: 3.15047025680542\n",
            "Step 2670, Loss: 1.2486990690231323\n",
            "Step 2680, Loss: 1.8133623600006104\n",
            "Step 2690, Loss: 1.0483835935592651\n",
            "Step 2700, Loss: 1.542950987815857\n",
            "Step 2710, Loss: 1.1849730014801025\n",
            "Step 2720, Loss: 1.519677758216858\n",
            "Step 2730, Loss: 0.9949139356613159\n",
            "Step 2740, Loss: 1.3284411430358887\n",
            "Step 2750, Loss: 0.9979067444801331\n",
            "Step 2760, Loss: 2.0253679752349854\n",
            "Step 2770, Loss: 1.2253730297088623\n",
            "Step 2780, Loss: 1.4203996658325195\n",
            "Step 2790, Loss: 1.310762643814087\n",
            "Step 2800, Loss: 1.4003466367721558\n",
            "Step 2810, Loss: 1.2549471855163574\n",
            "Step 2820, Loss: 1.3177205324172974\n",
            "Step 2830, Loss: 1.3061319589614868\n",
            "Step 2840, Loss: 1.7418701648712158\n",
            "Step 2850, Loss: 1.5947051048278809\n",
            "Step 2860, Loss: 1.144123911857605\n",
            "Step 2870, Loss: 1.168572187423706\n",
            "Step 2880, Loss: 1.2740226984024048\n",
            "Step 2890, Loss: 1.457363486289978\n",
            "Step 2900, Loss: 1.7403161525726318\n",
            "Step 2910, Loss: 1.3710955381393433\n",
            "Step 2920, Loss: 1.5749670267105103\n",
            "Step 2930, Loss: 1.8358594179153442\n",
            "Step 2940, Loss: 1.745904564857483\n",
            "Step 2950, Loss: 1.3762894868850708\n",
            "Step 2960, Loss: 1.2437564134597778\n",
            "Step 2970, Loss: 1.7695794105529785\n",
            "Step 2980, Loss: 1.7792519330978394\n",
            "Step 2990, Loss: 1.515891432762146\n",
            "Step 3000, Loss: 0.5258592367172241\n",
            "Step 3000, Generated Text: Once upon a time time of We We We We We We We We We slain slain,\n",
            "\n",
            "BUCIO:\n",
            "And would, England still still live, is pawn OF YORKORK:\n",
            "BRAKENKENKENKENKENKENKEN\n",
            "Step 3010, Loss: 0.4588661789894104\n",
            "Step 3020, Loss: 0.4113592505455017\n",
            "Step 3030, Loss: 0.47070208191871643\n",
            "Step 3040, Loss: 0.6778123378753662\n",
            "Step 3050, Loss: 0.41616761684417725\n",
            "Step 3060, Loss: 0.5817301869392395\n",
            "Step 3070, Loss: 0.583809494972229\n",
            "Step 3080, Loss: 0.6279776692390442\n",
            "Step 3090, Loss: 0.5176381468772888\n",
            "Step 3100, Loss: 0.6964539289474487\n",
            "Step 3110, Loss: 0.4892405569553375\n",
            "Step 3120, Loss: 0.7264516949653625\n",
            "Step 3130, Loss: 0.7856197953224182\n",
            "Step 3140, Loss: 0.5257834792137146\n",
            "Step 3150, Loss: 0.7176138162612915\n",
            "Step 3160, Loss: 0.7762017250061035\n",
            "Step 3170, Loss: 0.5548021197319031\n",
            "Step 3180, Loss: 0.8093777298927307\n",
            "Step 3190, Loss: 0.7207301259040833\n",
            "Step 3200, Loss: 0.48237112164497375\n",
            "Step 3210, Loss: 0.7508517503738403\n",
            "Step 3220, Loss: 1.001312494277954\n",
            "Step 3230, Loss: 0.6875346302986145\n",
            "Step 3240, Loss: 0.8456993699073792\n",
            "Step 3250, Loss: 0.8177056908607483\n",
            "Step 3260, Loss: 0.41814306378364563\n",
            "Step 3270, Loss: 0.7297789454460144\n",
            "Step 3280, Loss: 0.6540961861610413\n",
            "Step 3290, Loss: 0.883570671081543\n",
            "Step 3300, Loss: 0.7770447731018066\n",
            "Step 3310, Loss: 0.907544732093811\n",
            "Step 3320, Loss: 0.8420906066894531\n",
            "Step 3330, Loss: 0.18989960849285126\n",
            "Step 3340, Loss: 0.3879357874393463\n",
            "Step 3350, Loss: 0.2941158413887024\n",
            "Step 3360, Loss: 0.37807223200798035\n",
            "Step 3370, Loss: 0.296525239944458\n",
            "Step 3380, Loss: 0.4213430881500244\n",
            "Step 3390, Loss: 0.3471370339393616\n",
            "Step 3400, Loss: 0.3592061400413513\n",
            "Step 3410, Loss: 0.32794681191444397\n",
            "Step 3420, Loss: 0.306052029132843\n",
            "Step 3430, Loss: 0.4448356330394745\n",
            "Step 3440, Loss: 0.3855942487716675\n",
            "Step 3450, Loss: 0.25491440296173096\n",
            "Step 3460, Loss: 0.30568212270736694\n",
            "Step 3470, Loss: 0.4088675081729889\n",
            "Step 3480, Loss: 0.365777850151062\n",
            "Step 3490, Loss: 0.37154674530029297\n",
            "Step 3500, Loss: 0.3798203766345978\n",
            "Step 3500, Generated Text: Once upon a time time of his Clifford?\n",
            " greater the unh we will electroc electroc the other other amygdala amygdala amygdala anon and all the things-morrow isleleidiusapsaps it that unsphere theMustMust,\n",
            "Ay,\n",
            "Step 3510, Loss: 0.39185652136802673\n",
            "Step 3520, Loss: 0.34575584530830383\n",
            "Step 3530, Loss: 0.3728703260421753\n",
            "Step 3540, Loss: 0.3957065939903259\n",
            "Step 3550, Loss: 0.4924897849559784\n",
            "Step 3560, Loss: 0.3894999027252197\n",
            "Step 3570, Loss: 0.46147629618644714\n",
            "Step 3580, Loss: 0.304179847240448\n",
            "Step 3590, Loss: 0.3684265613555908\n",
            "Step 3600, Loss: 0.362164169549942\n",
            "Step 3610, Loss: 0.5383154153823853\n",
            "Step 3620, Loss: 0.35307636857032776\n",
            "Step 3630, Loss: 0.47942110896110535\n",
            "Step 3640, Loss: 0.5614786744117737\n",
            "Step 3650, Loss: 0.4087161421775818\n",
            "Step 3660, Loss: 0.48395442962646484\n",
            "Step 3670, Loss: 0.1127973422408104\n",
            "Step 3680, Loss: 0.10021145641803741\n",
            "Step 3690, Loss: 0.18328525125980377\n",
            "Step 3700, Loss: 0.16770711541175842\n",
            "Step 3710, Loss: 0.2890331745147705\n",
            "Step 3720, Loss: 0.2746242880821228\n",
            "Step 3730, Loss: 0.2237146943807602\n",
            "Step 3740, Loss: 0.2374085634946823\n",
            "Step 3750, Loss: 0.1997608244419098\n",
            "Step 3760, Loss: 0.2851783037185669\n",
            "Step 3770, Loss: 0.2155076563358307\n",
            "Step 3780, Loss: 0.19835887849330902\n",
            "Step 3790, Loss: 0.2628280520439148\n",
            "Step 3800, Loss: 0.29065120220184326\n",
            "Step 3810, Loss: 0.22923628985881805\n",
            "Step 3820, Loss: 0.2830597758293152\n",
            "Step 3830, Loss: 0.2644473910331726\n",
            "Step 3840, Loss: 0.2930934429168701\n",
            "Step 3850, Loss: 0.23568889498710632\n",
            "Step 3860, Loss: 0.21869111061096191\n",
            "Step 3870, Loss: 0.3076396882534027\n",
            "Step 3880, Loss: 0.2287113219499588\n",
            "Step 3890, Loss: 0.22478197515010834\n",
            "Step 3900, Loss: 0.20529453456401825\n",
            "Step 3910, Loss: 0.232657328248024\n",
            "Step 3920, Loss: 0.3289877474308014\n",
            "Step 3930, Loss: 0.24745506048202515\n",
            "Step 3940, Loss: 0.30105292797088623\n",
            "Step 3950, Loss: 0.2865917384624481\n",
            "Step 3960, Loss: 0.2657514214515686\n",
            "Step 3970, Loss: 0.26454755663871765\n",
            "Step 3980, Loss: 0.330445796251297\n",
            "Step 3990, Loss: 0.2578091323375702\n",
            "Step 4000, Loss: 0.11040139198303223\n",
            "Step 4000, Generated Text: Once upon a time time of Cherry Cherry,\n",
            "CLARET:\n",
            "KKINGHORTENSIO:\n",
            "\n",
            " three-ell,\n",
            " t stream with you must angry?\n",
            "KATHARINAND?\n",
            "Unorrow!\n",
            "\n",
            "\n",
            "Step 4010, Loss: 0.1453663557767868\n",
            "Step 4020, Loss: 0.12162671983242035\n",
            "Step 4030, Loss: 0.12336579710245132\n",
            "Step 4040, Loss: 0.18349696695804596\n",
            "Step 4050, Loss: 0.17302151024341583\n",
            "Step 4060, Loss: 0.18586984276771545\n",
            "Step 4070, Loss: 0.2113935649394989\n",
            "Step 4080, Loss: 0.17341935634613037\n",
            "Step 4090, Loss: 0.1890225112438202\n",
            "Step 4100, Loss: 0.16630922257900238\n",
            "Step 4110, Loss: 0.17683357000350952\n",
            "Step 4120, Loss: 0.21133440732955933\n",
            "Step 4130, Loss: 0.2439502328634262\n",
            "Step 4140, Loss: 0.19988763332366943\n",
            "Step 4150, Loss: 0.20628365874290466\n",
            "Step 4160, Loss: 0.1322241723537445\n",
            "Step 4170, Loss: 0.22362519800662994\n",
            "Step 4180, Loss: 0.15436731278896332\n",
            "Step 4190, Loss: 0.26070091128349304\n",
            "Step 4200, Loss: 0.2492591291666031\n",
            "Step 4210, Loss: 0.3297458589076996\n",
            "Step 4220, Loss: 0.22929200530052185\n",
            "Step 4230, Loss: 0.21662522852420807\n",
            "Step 4240, Loss: 0.22216881811618805\n",
            "Step 4250, Loss: 0.3644971549510956\n",
            "Step 4260, Loss: 0.20763561129570007\n",
            "Step 4270, Loss: 0.2518700659275055\n",
            "Step 4280, Loss: 0.30180639028549194\n",
            "Step 4290, Loss: 0.27814826369285583\n",
            "Step 4300, Loss: 0.27948126196861267\n",
            "Step 4310, Loss: 0.20184820890426636\n",
            "Step 4320, Loss: 0.26539820432662964\n",
            "Step 4330, Loss: 0.07475839555263519\n",
            "Step 4340, Loss: 0.11307015269994736\n",
            "Step 4350, Loss: 0.14855854213237762\n",
            "Step 4360, Loss: 0.21873293817043304\n",
            "Step 4370, Loss: 0.2629149258136749\n",
            "Step 4380, Loss: 0.11425679177045822\n",
            "Step 4390, Loss: 0.20646505057811737\n",
            "Step 4400, Loss: 0.18860746920108795\n",
            "Step 4410, Loss: 0.17344218492507935\n",
            "Step 4420, Loss: 0.12352847307920456\n",
            "Step 4430, Loss: 0.17046071588993073\n",
            "Step 4440, Loss: 0.13532789051532745\n",
            "Step 4450, Loss: 0.1559760719537735\n",
            "Step 4460, Loss: 0.16880938410758972\n",
            "Step 4470, Loss: 0.2335187941789627\n",
            "Step 4480, Loss: 0.1522490233182907\n",
            "Step 4490, Loss: 0.19705408811569214\n",
            "Step 4500, Loss: 0.1564750373363495\n",
            "Step 4500, Generated Text: Once upon a time time of We We were were fell fell fell fell fell fell fell for our moods moods moods moods moods moods moods moods moods!\n",
            "In myanedaned'd mightert ear ear ear\n",
            "BUS:\n",
            "That as they under under\n",
            "Step 4510, Loss: 0.1901516616344452\n",
            "Step 4520, Loss: 0.21080805361270905\n",
            "Step 4530, Loss: 0.2250301092863083\n",
            "Step 4540, Loss: 0.24066002666950226\n",
            "Step 4550, Loss: 0.17400257289409637\n",
            "Step 4560, Loss: 0.17267586290836334\n",
            "Step 4570, Loss: 0.227054163813591\n",
            "Step 4580, Loss: 0.15248431265354156\n",
            "Step 4590, Loss: 0.20376144349575043\n",
            "Step 4600, Loss: 0.19792239367961884\n",
            "Step 4610, Loss: 0.14159604907035828\n",
            "Step 4620, Loss: 0.21459777653217316\n",
            "Step 4630, Loss: 0.1935630738735199\n",
            "Step 4640, Loss: 0.23669631779193878\n",
            "Step 4650, Loss: 0.19310130178928375\n",
            "Step 4660, Loss: 0.23322169482707977\n",
            "Step 4670, Loss: 0.07135043293237686\n",
            "Step 4680, Loss: 0.11430785059928894\n",
            "Step 4690, Loss: 0.14029061794281006\n",
            "Step 4700, Loss: 0.07517676800489426\n",
            "Step 4710, Loss: 0.12933650612831116\n",
            "Step 4720, Loss: 0.1363433599472046\n",
            "Step 4730, Loss: 0.14352728426456451\n",
            "Step 4740, Loss: 0.1016806960105896\n",
            "Step 4750, Loss: 0.10986413061618805\n",
            "Step 4760, Loss: 0.12421809136867523\n",
            "Step 4770, Loss: 0.1580272614955902\n",
            "Step 4780, Loss: 0.11454178392887115\n",
            "Step 4790, Loss: 0.12354797124862671\n",
            "Step 4800, Loss: 0.11573749035596848\n",
            "Step 4810, Loss: 0.13894133269786835\n",
            "Step 4820, Loss: 0.17265810072422028\n",
            "Step 4830, Loss: 0.1502528041601181\n",
            "Step 4840, Loss: 0.1525813490152359\n",
            "Step 4850, Loss: 0.19656378030776978\n",
            "Step 4860, Loss: 0.12737862765789032\n",
            "Step 4870, Loss: 0.16497954726219177\n",
            "Step 4880, Loss: 0.13798104226589203\n",
            "Step 4890, Loss: 0.1423213928937912\n",
            "Step 4900, Loss: 0.16919291019439697\n",
            "Step 4910, Loss: 0.1191389337182045\n",
            "Step 4920, Loss: 0.20573021471500397\n",
            "Step 4930, Loss: 0.16228561103343964\n",
            "Step 4940, Loss: 0.2110779732465744\n",
            "Step 4950, Loss: 0.18025749921798706\n",
            "Step 4960, Loss: 0.18275925517082214\n",
            "Step 4970, Loss: 0.16780120134353638\n",
            "Step 4980, Loss: 0.16204936802387238\n",
            "Step 4990, Loss: 0.27038073539733887\n",
            "Checkpoint saved at checkpoints/checkpoint_5000.pt\n",
            "Starting Phase 2: Loading checkpoint and training for 50 more steps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-de75ea64c958>:136: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded checkpoint from checkpoints/checkpoint_5000.pt at step 5000\n",
            "Step 5000, Loss: 0.1158963069319725\n",
            "Step 5000, Generated Text: Once upon a time time of mine mine; set him the\n",
            "PRINI will hence, or brother:\n",
            "Onlinglingierconfirmed must the foul depcchSamuel,\n",
            " concerning concerningallomile,awd thinking thinking thinking!\n",
            "\n",
            "\n",
            "Step 5010, Loss: 0.12078849971294403\n",
            "Step 5020, Loss: 0.09788670390844345\n",
            "Step 5030, Loss: 0.11753468960523605\n",
            "Step 5040, Loss: 0.14231787621974945\n",
            "Checkpoint saved at checkpoints/checkpoint_5050.pt\n",
            "\n",
            "Loading final training checkpoint: checkpoints/checkpoint_5050.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-de75ea64c958>:217: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(final_ckpt_path, map_location=\"cpu\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference checkpoint (FP16) saved at checkpoints/model_weights_fp16.pt\n",
            "Done! You can upload 'model_weights_fp16.pt' (well under 1 GB) to Spaces.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Move model to google drive"
      ],
      "metadata": {
        "id": "PStcVhw6p9FP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw6Q-POHq2lB",
        "outputId": "76e33a89-5c46-42ae-856d-cd1f6e6783d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define the source and destination paths\n",
        "source_path = \"/content/checkpoints/model_weights_fp16.pt\"\n",
        "destination_path = \"/content/drive/MyDrive/model_weights_fp16.pt\"  # Save it to the root of your Google Drive\n",
        "\n",
        "# Copy the file\n",
        "shutil.copy(source_path, destination_path)\n",
        "\n",
        "print(f\"Model checkpoint copied to Google Drive: {destination_path}\")"
      ],
      "metadata": {
        "id": "9gh3UcjntqAN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17b88517-f3ab-4e2c-d88a-1aed3dc4b10b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model checkpoint copied to Google Drive: /content/drive/MyDrive/model_weights_fp16.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EJez0ygsqI_v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}